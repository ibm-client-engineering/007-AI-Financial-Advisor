{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"id": "a13c005e", "cell_type": "code", "source": "import pandas as pd\nfrom datetime import datetime, timedelta", "metadata": {"id": "01a06665-fa88-4ed0-be82-4557df7e1264"}, "outputs": [], "execution_count": 1}, {"id": "0e48325a", "cell_type": "markdown", "source": "### Data Loading", "metadata": {}}, {"id": "923206f7", "cell_type": "code", "source": "def load_and_clean_data():\n    \"\"\"\n    Load and clean datasets for further analysis.\n    \"\"\"\n    # Load datasets\n    import os\n    import types\n    import pandas as pd\n    from botocore.client import Config\n    import ibm_boto3\n\n    def __iter__(self): \n        return 0\n\n    # IBM Cloud Object Storage credentials\n    cos_client = ibm_boto3.client(\n        service_name='s3',\n        ibm_api_key_id='NYhoYyxMoqRAPvjF9EFNTyOfSasRKs4dIdeW5_aZwlg9',\n        ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n        config=Config(signature_version='oauth'),\n        endpoint_url='https://s3.direct.us-south.cloud-object-storage.appdomain.cloud'\n    )\n\n    bucket = '007tlhworkingproject-donotdelete-pr-hgvioy9vygrquk'\n\n    # Object keys and their corresponding dataframe names\n    object_keys = {\n        'transactions': 'Two_Years_Customer_Portfolio_Transactions_Data.csv',\n        'historical_prices': 'full_historical_prices.csv',\n        'customer_profiles': 'Customer_Profile.csv',\n        'tax_rates': 'Tax Rates.csv',\n        'stock_expanded_data': 'stock_expanded_data.csv'\n    }\n\n    dataframes = {}\n\n    # Reading each object into a pandas dataframe\n    for df_name, object_key in object_keys.items():\n        body = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n        if not hasattr(body, \"__iter__\"):\n            body.__iter__ = types.MethodType(__iter__, body)\n        dataframes[df_name] = pd.read_csv(body)\n\n    # Extract dataframes\n    transactions = dataframes['transactions']\n    historical_prices = dataframes['historical_prices']\n    customer_profiles = dataframes['customer_profiles']\n    tax_rates = dataframes['tax_rates']\n    stock_expanded_data = dataframes['stock_expanded_data']\n\n    # Ensure date columns are properly parsed\n    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"], errors=\"coerce\")\n    historical_prices[\"Date\"] = pd.to_datetime(historical_prices[\"Date\"], errors=\"coerce\")\n\n    return transactions, historical_prices, customer_profiles, tax_rates, stock_expanded_data\n\n# Call the function and load the datasets\noriginal_transactions, historical_prices, customer_profiles, tax_rates, stock_expanded_data = load_and_clean_data()\n", "metadata": {"id": "3e4dad21-7ff8-415b-87de-b6fbb34562e9"}, "outputs": [{"name": "stderr", "text": "/tmp/wsuser/ipykernel_438/88197021.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"], errors=\"coerce\")\n/tmp/wsuser/ipykernel_438/88197021.py:53: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n  historical_prices[\"Date\"] = pd.to_datetime(historical_prices[\"Date\"], errors=\"coerce\")\n", "output_type": "stream"}], "execution_count": 2}, {"id": "dc58ba8b", "cell_type": "markdown", "source": "### Helper Functions", "metadata": {}}, {"id": "8ebd432e", "cell_type": "code", "source": "def get_latest_prices(historical_data):\n    \"\"\"\n    Extract the latest prices for all tickers.\n    \"\"\"\n    latest_prices = (\n        historical_data.sort_values(by=[\"Ticker\", \"Date\"])\n        .groupby(\"Ticker\")[\"Close\"]\n        .last()\n        .to_dict()\n    )\n    return latest_prices\n\ndef calculate_holding_period(buy_date, sell_date):\n    \"\"\"\n    Calculate the holding period between buy and sell dates.\n    \"\"\"\n    return (sell_date - buy_date).days\n\ndef get_applicable_tax_rate(income, holding_period, tax_rate_table):\n    \"\"\"\n    Determine the applicable tax rate based on income and holding period.\n    \"\"\"\n    for _, row in tax_rate_table.iterrows():\n        lower_limit = row[\"Income Range-Lower Limit\"]\n        upper_limit = row[\"Income Range-Upper Limit\"]\n\n        # Handle the last row with no upper limit\n        if pd.isna(upper_limit) or income <= upper_limit:\n            if income >= lower_limit:\n                return (\n                    row[\"Long-Term Capital Gains Tax Rate\"]\n                    if holding_period > 365\n                    else row[\"Short-Term Capital Gains Tax Rate\"]\n                )\n    \n    # If income exceeds all ranges, use the last row\n    last_row = tax_rate_table.iloc[-1]\n    return (\n        last_row[\"Long-Term Capital Gains Tax Rate\"]\n        if holding_period > 365\n        else last_row[\"Short-Term Capital Gains Tax Rate\"]\n    )", "metadata": {"id": "c09a00a2-97d0-4f68-9764-2cd142934646"}, "outputs": [], "execution_count": 3}, {"id": "8d03e852", "cell_type": "markdown", "source": "### Portfolio Processing", "metadata": {}}, {"id": "42a1736c", "cell_type": "code", "source": "def compute_fifo_portfolio_with_metrics(transactions, current_prices, customer_id):\n    \"\"\"\n    Compute FIFO portfolio with unrealized gains/losses and metrics.\n    \"\"\"\n    transactions_filtered = transactions[transactions[\"Customer ID\"] == customer_id].copy()\n    transactions_filtered = transactions_filtered.sort_values(by=[\"Ticker\", \"Transaction Date\"])\n    \n    portfolio = []\n\n    for ticker, group in transactions_filtered.groupby(\"Ticker\"):\n        purchase_lots = []\n        remaining_quantity = 0\n        \n        for _, row in group.iterrows():\n            if row[\"Transaction Type\"] == \"Buy\":\n                purchase_lots.append((row[\"Quantity\"], row[\"Price\"], row[\"Transaction Date\"]))\n                remaining_quantity += row[\"Quantity\"]\n            elif row[\"Transaction Type\"] == \"Sell\":\n                sell_quantity = row[\"Quantity\"]\n                while sell_quantity > 0 and purchase_lots:\n                    lot_quantity, lot_price, lot_date = purchase_lots[0]\n                    if sell_quantity >= lot_quantity:\n                        sell_quantity -= lot_quantity\n                        remaining_quantity -= lot_quantity\n                        purchase_lots.pop(0)\n                    else:\n                        purchase_lots[0] = (lot_quantity - sell_quantity, lot_price, lot_date)\n                        remaining_quantity -= sell_quantity\n                        sell_quantity = 0\n\n        if remaining_quantity > 0:\n            total_cost = sum(lot[0] * lot[1] for lot in purchase_lots)\n            weighted_avg_price = total_cost / remaining_quantity\n            holding_periods = [\n                (lot[0] / remaining_quantity) * (datetime.now() - lot[2]).days for lot in purchase_lots\n            ]\n            avg_holding_period = sum(holding_periods)\n            current_price = current_prices.get(ticker, 0)\n            unrealized_gain_loss = (current_price - weighted_avg_price) * remaining_quantity\n\n            portfolio.append({\n                \"Ticker\": ticker,\n                \"Quantity\": remaining_quantity,\n                \"Purchase Price\": weighted_avg_price,\n                \"Current Price\": current_price,\n                \"Unrealized Gain/Loss\": unrealized_gain_loss,\n                \"Holding Period (Days)\": avg_holding_period\n            })\n\n    return pd.DataFrame(portfolio)", "metadata": {"id": "7e8fba28-badb-4b0b-9d98-2a1ce9cb592c"}, "outputs": [], "execution_count": 4}, {"id": "6d296402", "cell_type": "markdown", "source": "### Tax Loss Harvesting", "metadata": {}}, {"id": "346164e2", "cell_type": "code", "source": "def identify_tlh_candidates(portfolio):\n    \"\"\"\n    Identify TLH candidates with unrealized losses.\n    \"\"\"\n    return portfolio[portfolio[\"Unrealized Gain/Loss\"] < 0].sort_values(\"Unrealized Gain/Loss\")\n\ndef calculate_tax_savings(tlh_candidates, income, tax_rate_table):\n    \"\"\"\n    Calculate tax savings for TLH candidates.\n    \"\"\"\n    tlh_candidates[\"Tax Rate\"] = tlh_candidates.apply(\n        lambda row: get_applicable_tax_rate(income, row[\"Holding Period (Days)\"], tax_rate_table),\n        axis=1\n    )\n    tlh_candidates[\"Tax Savings\"] = -tlh_candidates[\"Unrealized Gain/Loss\"] * tlh_candidates[\"Tax Rate\"]\n    return tlh_candidates\n\ndef finalize_tlh_recommendation(tlh_candidates, realized_gains, max_loss_offset=3000):\n    total_offset_limit = realized_gains + max_loss_offset if realized_gains > 0 else max_loss_offset\n    remaining_offset = total_offset_limit\n\n    tlh_candidates[\"Tax Savings per Loss\"] = tlh_candidates[\"Tax Savings\"] / abs(tlh_candidates[\"Unrealized Gain/Loss\"])\n    tlh_candidates = tlh_candidates.sort_values(\n        by=[\"Tax Savings\", \"Tax Savings per Loss\"], ascending=[False, False]\n    )\n    tlh_candidates[\"Recommended\"] = False\n    tlh_candidates[\"Partial Quantity\"] = 0\n\n    for i, row in tlh_candidates.iterrows():\n        if remaining_offset <= 0:\n            break\n\n        # Calculate unrealized loss for the recommended quantity\n        unrealized_loss_per_unit = abs(row[\"Unrealized Gain/Loss\"] / row[\"Quantity\"])\n        max_quantity = int(remaining_offset / unrealized_loss_per_unit)\n\n        if abs(row[\"Unrealized Gain/Loss\"]) <= remaining_offset:\n            tlh_candidates.at[i, \"Recommended\"] = True\n            tlh_candidates.at[i, \"Partial Quantity\"] = row[\"Quantity\"]\n            remaining_offset -= abs(row[\"Unrealized Gain/Loss\"])\n        elif max_quantity > 0:\n            tlh_candidates.at[i, \"Recommended\"] = True\n            tlh_candidates.at[i, \"Partial Quantity\"] = max_quantity\n            remaining_offset = 0\n\n    return tlh_candidates\n\n\ndef calculate_realized_gains(transactions, customer_id, tax_year):\n    \"\"\"\n    Calculate realized gains for sell transactions in a given tax year using FIFO logic.\n\n    Args:\n        transactions (DataFrame): Full transaction data.\n        customer_id (str): Customer ID for filtering.\n        tax_year (int): Tax year for capital gains calculation.\n\n    Returns:\n        float: Total realized gains for the tax year.\n    \"\"\"\n    # Filter transactions for the customer and the given tax year\n    transactions = transactions[transactions[\"Customer ID\"] == customer_id]\n    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n    sell_transactions = transactions[\n        (transactions[\"Transaction Type\"] == \"Sell\") &\n        (transactions[\"Transaction Date\"].dt.year == tax_year)\n    ]\n    \n    # Group buy transactions for FIFO matching\n    buy_transactions = transactions[\n        (transactions[\"Transaction Type\"] == \"Buy\")\n    ].sort_values(by=\"Transaction Date\")\n\n    realized_gains = 0\n\n    # FIFO logic for calculating gains\n    for _, sell in sell_transactions.iterrows():\n        ticker = sell[\"Ticker\"]\n        quantity_to_sell = sell[\"Quantity\"]\n        sell_price = sell[\"Price\"]\n\n        for _, buy in buy_transactions[buy_transactions[\"Ticker\"] == ticker].iterrows():\n            if quantity_to_sell <= 0:\n                break\n\n            buy_quantity = buy[\"Quantity\"]\n            buy_price = buy[\"Price\"]\n            matched_quantity = min(quantity_to_sell, buy_quantity)\n            realized_gains += (sell_price - buy_price) * matched_quantity\n            quantity_to_sell -= matched_quantity\n\n            # Adjust remaining buy quantity\n            buy_transactions.loc[buy.name, \"Quantity\"] -= matched_quantity\n\n    return realized_gains\n\n\ndef calculate_sales_and_gains_summary(transactions, customer_id, tax_year):\n    \"\"\"\n    Calculate total sales, realized gains, percent return, and top 3 stocks by return for a given tax year using FIFO logic.\n\n    Args:\n        transactions (DataFrame): Full transaction data.\n        customer_id (str): Customer ID for filtering.\n        tax_year (int): Tax year for calculations.\n\n    Returns:\n        str: Formatted summary string with sales, realized gains, percent return, and top 3 stocks.\n    \"\"\"\n    # Filter transactions for the customer and the given tax year\n    transactions = transactions[transactions[\"Customer ID\"] == customer_id]\n    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n    sell_transactions = transactions[\n        (transactions[\"Transaction Type\"] == \"Sell\") &\n        (transactions[\"Transaction Date\"].dt.year == tax_year)\n    ]\n\n    # Group buy transactions for FIFO matching\n    buy_transactions = transactions[\n        (transactions[\"Transaction Type\"] == \"Buy\")\n    ].sort_values(by=\"Transaction Date\")\n\n    total_sales = 0\n    realized_gains = 0\n    stock_returns = []\n\n    # FIFO logic for calculating gains\n    for _, sell in sell_transactions.iterrows():\n        ticker = sell[\"Ticker\"]\n        quantity_to_sell = sell[\"Quantity\"]\n        sell_price = sell[\"Price\"]\n\n        total_sale_for_ticker = 0\n        total_cost_for_ticker = 0\n\n        for _, buy in buy_transactions[buy_transactions[\"Ticker\"] == ticker].iterrows():\n            if quantity_to_sell <= 0:\n                break\n\n            buy_quantity = buy[\"Quantity\"]\n            buy_price = buy[\"Price\"]\n            matched_quantity = min(quantity_to_sell, buy_quantity)\n\n            # Calculate realized gains\n            realized_gains += (sell_price - buy_price) * matched_quantity\n\n            # Track sales and costs for this ticker\n            total_sale_for_ticker += sell_price * matched_quantity\n            total_cost_for_ticker += buy_price * matched_quantity\n\n            quantity_to_sell -= matched_quantity\n\n            # Adjust remaining buy quantity\n            buy_transactions.loc[buy.name, \"Quantity\"] -= matched_quantity\n\n        # Record return for the ticker if sales occurred\n        if total_cost_for_ticker > 0:\n            percent_return = ((total_sale_for_ticker - total_cost_for_ticker) / total_cost_for_ticker) * 100\n            stock_returns.append((ticker, percent_return, total_sale_for_ticker))\n\n        # Add to total sales\n        total_sales += total_sale_for_ticker\n\n    # Get top 3 stocks by return\n    top_3_stocks = sorted(stock_returns, key=lambda x: x[1], reverse=True)[:3]\n\n    # Calculate overall percent return\n    overall_percent_return = ((realized_gains / total_sales) * 100) if total_sales > 0 else 0\n\n    # Build the formatted summary string\n    summary = f\"Total Sales Made: ${total_sales:,.2f}\\n\"\n    summary += f\"Realized Gains: ${realized_gains:,.2f}\\n\"\n    summary += f\"Overall Percent Return: {overall_percent_return:.2f}%\\n\"\n    summary += \"Top 3 Stocks by Return:\\n\"\n    for ticker, percent_return, total_sales in top_3_stocks:\n        summary += f\"  {ticker}: {percent_return:.2f}% return, Total Sales: ${total_sales:,.2f}\\n\"\n\n    return summary\n\n", "metadata": {"id": "d4d69938-1b3d-4244-b77f-d16e7eabe7ab"}, "outputs": [], "execution_count": 5}, {"id": "cadba3d7", "cell_type": "markdown", "source": "### Wash Sale Detection", "metadata": {}}, {"id": "cef5dcad", "cell_type": "code", "source": "def detect_wash_sales(transactions, tlh_candidates):\n    \"\"\"\n    Detect wash sale violations for TLH candidates and provide detailed warnings.\n\n    Args:\n        transactions (DataFrame): Transaction data containing all trades.\n        tlh_candidates (DataFrame): TLH candidates being evaluated.\n\n    Returns:\n        Tuple: (List of detailed warnings, List of tickers with wash-sale violations)\n    \"\"\"\n    warnings = []\n    wash_sale_tickers = []  # To store tickers with wash sale warnings\n\n    for _, row in tlh_candidates.iterrows():\n        ticker = row[\"Ticker\"]\n        sale_date = datetime.now()  # Assume current date for sale\n        # Filter transactions for recent buys within the last 30 days\n        recent_buys = transactions[\n            (transactions[\"Ticker\"] == ticker) &\n            (transactions[\"Transaction Type\"] == \"Buy\") &\n            (transactions[\"Transaction Date\"] >= sale_date - timedelta(days=30))\n        ]\n        if not recent_buys.empty:\n            # Find the most recent purchase date\n            most_recent_buy_date = recent_buys[\"Transaction Date\"].max()\n            safe_sell_date = most_recent_buy_date + timedelta(days=31)\n            warnings.append(\n                f\"Wash sale warning: Recent buy detected for {ticker} on {most_recent_buy_date.date()}. \"\n                f\"You can safely sell after {safe_sell_date.date()} to avoid violations.\"\n            )\n            wash_sale_tickers.append(ticker)  # Add ticker to the list\n\n    return warnings, wash_sale_tickers", "metadata": {"id": "f9d719d0-3272-43c1-99b9-f9b654bfd73f"}, "outputs": [], "execution_count": 6}, {"id": "1eee2444", "cell_type": "markdown", "source": "### Reinvestment Recommendation System", "metadata": {}}, {"id": "4554792a", "cell_type": "code", "source": "def identify_stocks_to_sell(portfolio, customer_preferences):\n    \"\"\"\n    Identify stocks to sell based on risk tolerance, sectors, and investment goals.\n    \"\"\"\n    # Extract preferences\n    risk_tolerance = customer_preferences[\"Risk Tolerance\"]\n    preferred_sectors = customer_preferences[\"Preferred Sectors\"]\n\n    # Convert sectors to a list if it's a string\n    if isinstance(preferred_sectors, str):\n        preferred_sectors = [sector.strip() for sector in preferred_sectors.split(\",\")]\n\n    # Filter based on risk tolerance\n    if risk_tolerance == \"Low\":\n        portfolio = portfolio[portfolio[\"Beta\"] < 1]\n    elif risk_tolerance == \"Moderate\":\n        portfolio = portfolio[(portfolio[\"Beta\"] >= 1) & (portfolio[\"Beta\"] <= 1.5)]\n    elif risk_tolerance == \"High\":\n        portfolio = portfolio[portfolio[\"Beta\"] > 1.5]\n\n    # Filter non-preferred sectors\n    portfolio = portfolio[~portfolio[\"Sector\"].isin(preferred_sectors)]\n\n    return portfolio\n\ndef recommend_reinvestment_stocks_with_details(available_balance, stock_data, wash_sale_tickers, customer_preferences, max_stock_allocation_pct=0.15, max_sector_allocation_pct=0.30):\n    \"\"\"\n    Recommend stocks for reinvestment while providing detailed information like purchase quantity, current price, YTD returns, and other metrics.\n    \"\"\"\n    latest_prices = get_latest_prices(historical_prices)\n    latest_prices = pd.DataFrame.from_dict(latest_prices, orient=\"index\", columns=[\"Current Price\"]).reset_index().rename(columns={\"index\": \"Ticker\"})\n    stock_data = stock_data.merge(latest_prices, on=\"Ticker\", how=\"left\")\n\n    # Exclude wash-sale-triggering stocks\n    stock_data = stock_data[~stock_data[\"Ticker\"].isin(wash_sale_tickers)]\n    \n    stock_data = stock_data[stock_data[\"YTD Return (%)\"] > 0]\n\n    # Convert preferred sectors to a list if it's a string\n    preferred_sectors = customer_preferences[\"Preferred Sectors\"]\n    if isinstance(preferred_sectors, str):\n        preferred_sectors = [sector.strip() for sector in preferred_sectors.split(\",\")]\n\n    # Filter by sector preference\n    stock_data = stock_data[stock_data[\"Sector\"].isin(preferred_sectors)]\n\n    # Filter by risk tolerance\n    risk_tolerance = customer_preferences[\"Risk Tolerance\"]\n    if risk_tolerance == \"Low\":\n        stock_data = stock_data[stock_data[\"Beta\"] < 1]\n    elif risk_tolerance == \"Moderate\":\n        stock_data = stock_data[(stock_data[\"Beta\"] >= 1) & (stock_data[\"Beta\"] <= 1.5)]\n    elif risk_tolerance == \"High\":\n        stock_data = stock_data[stock_data[\"Beta\"] > 1.5]\n\n    # Rank stocks by customer goals\n    if customer_preferences[\"Investment Goals\"] == \"Dividend Income\":\n        stock_data = stock_data.sort_values(by=\"Dividend Yield (%)\", ascending=False)\n    elif customer_preferences[\"Investment Goals\"] == \"Growth\":\n        stock_data = stock_data.sort_values(by=\"Growth Rate\", ascending=False)\n\n    # Allocation logic\n    allocation = []\n    sector_allocations = {}\n\n    for _, row in stock_data.iterrows():\n        # Calculate max allocations\n        max_stock_allocation = available_balance * max_stock_allocation_pct\n        max_sector_allocation = available_balance * max_sector_allocation_pct\n\n        # Get current sector allocation\n        current_sector_allocation = sector_allocations.get(row[\"Sector\"], 0)\n        remaining_sector_allocation = max_sector_allocation - current_sector_allocation\n\n        # Allocate funds while respecting constraints\n        allocation_amount = min(max_stock_allocation, remaining_sector_allocation, available_balance)\n        if allocation_amount > 0:\n            # Calculate purchase quantity\n            purchase_quantity = allocation_amount // row[\"Current Price\"]\n            allocation_amount = purchase_quantity * row[\"Current Price\"]  # Recalculate based on whole shares\n\n            allocation.append({\n                \"Ticker\": row[\"Ticker\"],\n                \"Allocation\": allocation_amount,\n                \"Purchase Quantity\": purchase_quantity,\n                \"Current Price\": row[\"Current Price\"],\n                \"YTD Return\": row[\"YTD Return (%)\"],\n                \"P/E Ratio\": row.get(\"P/E Ratio\", \"N/A\"),\n                \"Market Cap (B)\": row.get(\"Market Cap (B)\", \"N/A\"),\n                \"Beta\": row.get(\"Beta\", \"N/A\"),\n                \"52-Week High\": row.get(\"52-Week High\", \"N/A\"),\n                \"52-Week Low\": row.get(\"52-Week Low\", \"N/A\"),\n                \"Growth Rate\": row.get(\"Growth Rate\",\"N/A\"),\n                \"Projected Growth\": allocation_amount * (1 + row[\"Growth Rate\"])\n            })\n\n            # Update balances\n            available_balance -= allocation_amount\n            sector_allocations[row[\"Sector\"]] = current_sector_allocation + allocation_amount\n\n        # Stop if all funds are allocated\n        if available_balance <= 0:\n            break\n\n    # Redistribute residual balance proportionally if any remains\n    if available_balance > 0:\n        total_allocation = sum(a[\"Allocation\"] for a in allocation)\n        for entry in allocation:\n            proportional_addition = (entry[\"Allocation\"] / total_allocation) * available_balance\n            entry[\"Allocation\"] += proportional_addition\n            entry[\"Purchase Quantity\"] += int(proportional_addition // entry[\"Current Price\"])\n            entry[\"Projected Growth\"] = entry[\"Allocation\"] * (1 + stock_data.loc[stock_data[\"Ticker\"] == entry[\"Ticker\"], \"Growth Rate\"].values[0])\n    \n    # Filter out zero-allocation stocks\n    allocation_df = pd.DataFrame(allocation)\n    allocation_df = allocation_df[allocation_df[\"Allocation\"] > 0]\n    allocation_df = allocation_df.drop(columns=[\"Allocation\"], errors=\"ignore\")\n\n    return allocation_df\n\n", "metadata": {"id": "9fa3ef10-4663-4db7-b850-9658e2974375"}, "outputs": [], "execution_count": 7}, {"id": "5e00d45b", "cell_type": "markdown", "source": "### Execute code and Convert all data to JSON for Watsonx Discovery", "metadata": {}}, {"id": "0a520573", "cell_type": "code", "source": "import pandas as pd\nimport json\nimport re\n\n# Assume all necessary modules and functions are already imported\n# and original_transactions, customer_profiles, historical_prices,\n# tax_rates, stock_expanded_data, etc., are already defined.\n\nall_customers_data = []\n\n# Function to reset data before processing each customer\ndef reset_data():\n    global transactions\n    transactions = original_transactions.copy()\n    # Repeat for other DataFrames if necessary\n\n# Function to process a single customer\ndef process_customer(customer_id):\n    # Reset data before processing each customer\n    reset_data()\n    \n    tax_year = 2024  # Use the current or target tax year\n\n    # Extract the customer's profile\n    customer_profile = customer_profiles[customer_profiles[\"Customer ID\"] == customer_id].iloc[0]\n    \n    # Extract user preferences\n    risk_tolerance = customer_profile[\"Risk Tolerance\"]\n    preferred_sectors = customer_profile[\"Preferred Sectors\"].split(\", \")\n    investment_goals = customer_profile[\"Investment Goals\"]\n    current_prices = get_latest_prices(historical_prices)\n    income = customer_profile[\"Annual Income\"]\n    \n    # Calculate the customer's portfolio\n    portfolio = compute_fifo_portfolio_with_metrics(transactions, current_prices, customer_id)\n    \n    # Identify TLH candidates\n    tlh_candidates = identify_tlh_candidates(portfolio)\n    \n    # Calculate tax savings for TLH candidates\n    tlh_candidates_with_savings = calculate_tax_savings(tlh_candidates, income, tax_rates)\n    \n    # Calculate realized gains dynamically from transactions\n    realized_gains = calculate_realized_gains(transactions, customer_id, tax_year)\n    \n    # Generate final TLH recommendations\n    final_tlh_recommendations = finalize_tlh_recommendation(\n        tlh_candidates_with_savings,\n        realized_gains,\n        max_loss_offset=3000\n    )\n    \n    # Detect potential wash sale violations\n    wash_sale_warnings, wash_sale_tickers = detect_wash_sales(transactions, tlh_candidates_with_savings)\n    \n    # Calculate the sale proceeds for reinvestment\n    final_tlh_recommendations[\"Sale Proceeds\"] = (\n        final_tlh_recommendations[\"Partial Quantity\"] * final_tlh_recommendations[\"Current Price\"]\n    )\n    available_balance = final_tlh_recommendations[\"Sale Proceeds\"].sum()\n    \n    # Identify stocks to sell (if applicable)\n    # stocks_to_sell = identify_stocks_to_sell(stock_expanded_data, customer_profile)\n    \n    # Filter stocks based on customer preferences\n    recommended_stocks = recommend_reinvestment_stocks_with_details(\n        available_balance, stock_expanded_data, wash_sale_tickers, customer_profile\n    )\n    \n    # --- Portfolio Summary ---\n    portfolio_updated = portfolio.drop(columns=[\"Holding Period (Days)\"])\n    going_well = portfolio_updated[portfolio_updated[\"Unrealized Gain/Loss\"] > 0]\n    \n    going_bad = portfolio_updated[portfolio_updated[\"Unrealized Gain/Loss\"] < 0].copy()\n    going_bad['Unrealized Gain/Loss'] = going_bad['Unrealized Gain/Loss'].abs()\n    going_bad.rename(columns={'Unrealized Gain/Loss':'Unrealized Loss'}, inplace=True)\n    going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)\n    \n    # Calculate Total Investments\n    portfolio[\"Initial Investment\"] = portfolio[\"Purchase Price\"] * portfolio[\"Quantity\"]\n    portfolio[\"Current Value\"] = portfolio[\"Current Price\"] * portfolio[\"Quantity\"]\n    total_initial_investment = portfolio[\"Initial Investment\"].sum()\n    total_current_value = portfolio[\"Current Value\"].sum()\n    net_unrealized_gain_loss_percent = (\n        (portfolio[\"Unrealized Gain/Loss\"].sum() / portfolio[\"Initial Investment\"].sum()) * 100\n    ).round(2)\n    \n    # Sales made in the tax year\n    customer_transactions = transactions[transactions[\"Customer ID\"] == customer_id].copy()\n    customer_transactions[\"Transaction Date\"] = pd.to_datetime(customer_transactions[\"Transaction Date\"])\n    sell_transactions = customer_transactions[\n        (customer_transactions[\"Transaction Type\"] == \"Sell\") &\n        (customer_transactions[\"Transaction Date\"].dt.year == tax_year)\n    ]\n    \n    # Calculate sales and gains summary\n    summary = calculate_sales_and_gains_summary(transactions, customer_id, tax_year)\n    total_sales = re.search(r\"Total Sales Made: \\$(\\d[\\d,\\.]*)\", summary).group(1)\n    realized_gains_str = re.search(r\"Realized Gains: \\$(\\d[\\d,\\.]*)\", summary).group(1)\n    overall_percent_return = re.search(r\"Overall Percent Return: ([\\d\\.]*)%\", summary).group(1)\n    top_stocks = re.findall(r\"(\\w+): ([\\d\\.]+)% return, Total Sales: \\$(\\d[\\d,\\.]*)\", summary)\n    realized_gains_float = float(realized_gains_str.replace(\",\", \"\")) if isinstance(realized_gains_str, str) else float(realized_gains_str)\n    \n    # --- Tax Loss Harvesting Analysis ---\n    # Generate TLH Table with Additional Columns\n    tlh_table = final_tlh_recommendations[[\n        \"Ticker\", \"Unrealized Gain/Loss\", \"Partial Quantity\", \"Current Price\", \"Recommended\", \"Sale Proceeds\"\n    ]].copy()\n    \n    # Calculate Absolute Losses\n    tlh_table[\"Unrealized Gain/Loss\"] = tlh_table[\"Unrealized Gain/Loss\"].abs()\n    tlh_table.rename(columns={\n        \"Unrealized Gain/Loss\": \"Losses\",\n        \"Partial Quantity\": \"Quantity to Sell\"\n    }, inplace=True)\n    \n    # Calculate Total Tax Savings\n    total_tax_savings = final_tlh_recommendations[final_tlh_recommendations[\"Recommended\"]][\"Tax Savings\"].sum()\n    \n    # Calculate Total Sale Proceeds from TLH Sales\n    total_sale_proceeds = final_tlh_recommendations[final_tlh_recommendations[\"Recommended\"]][\"Sale Proceeds\"].sum()\n    \n    # Generate Wash Sale Output\n    wash_sale_output = \"\\n\".join(wash_sale_warnings) if wash_sale_warnings else \"No wash sale warnings.\"\n    \n    # Calculate Total Offset Limit\n    total_offset_limit = realized_gains_float + 3000 if realized_gains_float > 0 else 3000\n    \n    # --- Reinvestment Recommendations ---\n    # Reinvest amount\n    total_investment = (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Current Price\"]).sum()\n    \n    # Add Allocation (%) column\n    recommended_stocks[\"Allocation (%)\"] = (\n        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Current Price\"]) / total_investment * 100\n    )\n    \n    # Calculate Weighted YTD Return\n    weighted_ytd_return = (\n        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"YTD Return\"]).sum() /\n        recommended_stocks[\"Purchase Quantity\"].sum()\n    )\n    \n    # Calculate Portfolio Beta\n    portfolio_beta = (\n        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Beta\"]).sum() /\n        recommended_stocks[\"Purchase Quantity\"].sum()\n    )\n    \n    # Calculate Average P/E Ratio\n    average_pe_ratio = recommended_stocks[\"P/E Ratio\"].mean()\n    \n    # Calculate Average Growth Rate\n    average_growth_rate = recommended_stocks[\"Growth Rate\"].mean()\n    \n    # Create the Recommendations Table\n    recommendations_table = recommended_stocks[\n        [\"Ticker\", \"Purchase Quantity\", \"Current Price\", \"YTD Return\", \"Beta\", \"P/E Ratio\", \"Growth Rate\", \"Allocation (%)\"]\n    ].copy()\n    \n    # Round numbers where needed\n    recommendations_table[\"Allocation (%)\"] = recommendations_table[\"Allocation (%)\"].round(2)\n    weighted_ytd_return = round(weighted_ytd_return, 2)\n    portfolio_beta = round(portfolio_beta, 2)\n    average_pe_ratio = round(average_pe_ratio, 2)\n    average_growth_rate = round(average_growth_rate, 2)\n    recommendations_table[\"YTD Return\"] = recommendations_table[\"YTD Return\"].round(2)\n    recommendations_table[\"Growth Rate\"] = recommendations_table[\"Growth Rate\"].round(2)\n    recommendations_table[\"Current Price\"] = recommendations_table[\"Current Price\"].round(2)\n    recommendations_table[\"P/E Ratio\"] = recommendations_table[\"P/E Ratio\"].round(2)\n    recommendations_table[\"Beta\"] = recommendations_table[\"Beta\"].round(2)\n    \n    # --- Executive Summary ---\n    net_unrealized_gain_loss = portfolio[\"Unrealized Gain/Loss\"].sum().round(2)\n    recommendations_stocks = recommended_stocks[\"Ticker\"]\n    expected_average_growth_rate = average_growth_rate\n    \n    # --- Convert all data to JSON ---\n    output_data = {\n        \"Customer ID\": customer_id,\n        \"Executive Summary\": {\n            \"Customer Profile\": {\n                \"Risk Tolerance\": customer_profile[\"Risk Tolerance\"],\n                \"Preferred Sectors\": customer_profile[\"Preferred Sectors\"],\n                \"Investment Goals\": customer_profile[\"Investment Goals\"],\n            },\n            \"Portfolio Summary\": {\n                \"Total Current Value\": round(total_current_value, 2),\n                \"Net Unrealized Gain/Loss\": round(net_unrealized_gain_loss, 2),\n            },\n            \"Tax-Loss Harvesting\": {\n                \"Total Tax Savings\": round(total_tax_savings, 2),\n                \"Reinvestment Amount\": round(total_sale_proceeds, 2),\n            },\n            \"Reinvestment Recommendations\": {\n                \"Recommended Stocks\": recommendations_stocks.tolist(),\n                \"Expected Average Growth Rate %\": round(expected_average_growth_rate, 2),\n            },\n        },\n        \"Portfolio Summary\": {\n            \"Total Initial Investment\": round(total_initial_investment, 2),\n            \"Total Current Value\": round(total_current_value, 2),\n            \"Net Unrealized Gain/Loss Percent\": round(net_unrealized_gain_loss_percent, 2),\n            \"Going Bad Investments\": [\n                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}\n            for record in going_bad.to_dict(orient=\"records\")\n            ],\n            \"Going Well Investments\": [\n                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}\n            for record in going_well.to_dict(orient=\"records\")\n            ],\n            \"Sales Analysis\": {\n                \"Total Sales Made\": round(float(total_sales.replace(\",\", \"\")), 2),\n                \"Realized Gains\": round(realized_gains_float, 2),\n                \"Overall Percent Return\": round(float(overall_percent_return), 2),\n                \"Top Stocks by Return\": [\n                    {\n                        \"Ticker\": stock[0],\n                        \"Return Percent\": round(float(stock[1]), 2),\n                        \"Total Sales\": round(float(stock[2].replace(\",\", \"\")), 2),\n                    }\n                    for stock in top_stocks\n                ],\n            },\n        },\n        \"Tax Loss Harvesting Analysis\": {\n            \"Table\": [\n                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}\n            for record in tlh_table.to_dict(orient=\"records\")\n            ],\n            \"Total Tax Savings\": round(total_tax_savings, 2),\n            \"Total Sale Proceeds from TLH Sales\": round(total_sale_proceeds, 2),\n            \"Wash Sale Warnings\": wash_sale_warnings,\n        },\n        \"Reinvestment Recommendations\": {\n            \"Customer Profile\": {\n                \"Risk Tolerance\": customer_profile[\"Risk Tolerance\"],\n                \"Preferred Sectors\": customer_profile[\"Preferred Sectors\"],\n                \"Investment Goals\": customer_profile[\"Investment Goals\"],\n            },\n            \"Table\": [\n                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}\n            for record in recommendations_table.to_dict(orient=\"records\")\n            ],\n            \"New Portfolio Summary\": {\n                \"Total Investment\": round(total_investment, 2),\n                \"Weighted YTD Return\": weighted_ytd_return,\n                \"Portfolio Beta\": portfolio_beta,\n                \"Average P/E Ratio\": average_pe_ratio,\n                \"Expected Average Growth Rate\": average_growth_rate,\n            },\n        },\n    }\n    \n    # Instead of writing to a file, append the output_data to the list\n    all_customers_data.append(output_data)\n    \n    print(f\"Processed customer {customer_id}\")\n\n# Get a list of all customer IDs\ncustomer_ids = customer_profiles[\"Customer ID\"].unique()\n\n# Loop over all customer IDs and process each one\nfor customer_id in customer_ids:\n    process_customer(customer_id)\n\n# After processing all customers, write the accumulated data to a single JSON file\nwith open(\"all_customers_report.json\", \"w\") as file:\n    json.dump(all_customers_data, file, indent=4)\n\nprint(\"All customer data has been written to 'all_customers_report.json'\")", "metadata": {"scrolled": true, "id": "f85fbb0d-7df9-423f-9477-f7d67ec04d67"}, "outputs": [{"name": "stdout", "text": "Processed customer C001\nProcessed customer C002\nAll customer data has been written to 'all_customers_report.json'\n", "output_type": "stream"}, {"name": "stderr", "text": "/tmp/wsuser/ipykernel_438/2890460161.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/3882620736.py:77: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)\n/tmp/wsuser/ipykernel_438/2890460161.py:112: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/2890460161.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/3882620736.py:77: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)\n/tmp/wsuser/ipykernel_438/2890460161.py:112: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n", "output_type": "stream"}], "execution_count": 8}, {"id": "441d7321-fe91-450b-8a16-793436e2f3e7", "cell_type": "code", "source": "import json\nimport ibm_boto3\nfrom ibm_botocore.client import Config\n\n# IBM COS Credentials and Configurations\nCOS_API_KEY = \"RuSq2hb5DI8kOl1ZznOxQHx3igYJObJF-yTHDDkNi55E\"  # Replace with your IBM COS API Key\nCOS_ENDPOINT = \"https://s3.direct.us-south.cloud-object-storage.appdomain.cloud\"  # Replace with your endpoint\nCOS_BUCKET_NAME = \"007tlhdata\"  # Replace with your bucket name\nCOS_OBJECT_NAME = \"json_customer_data/all_customers_data.json\"  # Name of the file to be saved in COS\n\n# Initialize COS client\ncos_client = ibm_boto3.client(\n    service_name=\"s3\",\n    ibm_api_key_id=COS_API_KEY,\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n    config=Config(signature_version=\"oauth\"),\n    endpoint_url=COS_ENDPOINT,\n)\n\n# Convert JSON to a string\njson_data = json.dumps(all_customers_data)\n\n# Upload the JSON file to IBM COS\ntry:\n    response = cos_client.put_object(\n        Bucket=COS_BUCKET_NAME,\n        Key=COS_OBJECT_NAME,\n        Body=json_data,\n        ContentType=\"application/json\",\n    )\n    print(f\"Upload Successful! ETag: {response['ETag']}\")\nexcept Exception as e:\n    print(f\"Error uploading file: {e}\")\n", "metadata": {"id": "441d7321-fe91-450b-8a16-793436e2f3e7"}, "outputs": [{"name": "stdout", "text": "Upload Successful! ETag: \"1abb7028705e029d39029b84725f09f8\"\n", "output_type": "stream"}], "execution_count": 9}]}