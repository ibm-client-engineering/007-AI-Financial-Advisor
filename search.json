[
  {
    "objectID": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:TLH_Rebalancing_Portfolio-Final_6rNNv_ZpS.html",
    "href": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:TLH_Rebalancing_Portfolio-Final_6rNNv_ZpS.html",
    "title": "Data Loading",
    "section": "",
    "text": "import pandas as pdfrom datetime import datetime, timedelta\n\n\ndef load_and_clean_data():    \"\"\"    Load and clean datasets for further analysis.    \"\"\"    # Load datasets    import os    import types    import pandas as pd    from botocore.client import Config    import ibm_boto3    def __iter__(self):         return 0    # IBM Cloud Object Storage credentials    cos_client = ibm_boto3.client(        service_name='s3',        ibm_api_key_id='NYhoYyxMoqRAPvjF9EFNTyOfSasRKs4dIdeW5_aZwlg9',        ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",        config=Config(signature_version='oauth'),        endpoint_url='https://s3.direct.us-south.cloud-object-storage.appdomain.cloud'    )    bucket = '007tlhworkingproject-donotdelete-pr-hgvioy9vygrquk'    # Object keys and their corresponding dataframe names    object_keys = {        'transactions': 'Two_Years_Customer_Portfolio_Transactions_Data.csv',        'historical_prices': 'full_historical_prices.csv',        'customer_profiles': 'Customer_Profile.csv',        'tax_rates': 'Tax Rates.csv',        'stock_expanded_data': 'stock_expanded_data.csv'    }    dataframes = {}    # Reading each object into a pandas dataframe    for df_name, object_key in object_keys.items():        body = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']        if not hasattr(body, \"__iter__\"):            body.__iter__ = types.MethodType(__iter__, body)        dataframes[df_name] = pd.read_csv(body)    # Extract dataframes    transactions = dataframes['transactions']    historical_prices = dataframes['historical_prices']    customer_profiles = dataframes['customer_profiles']    tax_rates = dataframes['tax_rates']    stock_expanded_data = dataframes['stock_expanded_data']    # Ensure date columns are properly parsed    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"], errors=\"coerce\")    historical_prices[\"Date\"] = pd.to_datetime(historical_prices[\"Date\"], errors=\"coerce\")    return transactions, historical_prices, customer_profiles, tax_rates, stock_expanded_data# Call the function and load the datasetsoriginal_transactions, historical_prices, customer_profiles, tax_rates, stock_expanded_data = load_and_clean_data()\n\n/tmp/wsuser/ipykernel_438/88197021.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"], errors=\"coerce\")\n/tmp/wsuser/ipykernel_438/88197021.py:53: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n  historical_prices[\"Date\"] = pd.to_datetime(historical_prices[\"Date\"], errors=\"coerce\")\n\n\n\nHelper Functions\n\ndef get_latest_prices(historical_data):    \"\"\"    Extract the latest prices for all tickers.    \"\"\"    latest_prices = (        historical_data.sort_values(by=[\"Ticker\", \"Date\"])        .groupby(\"Ticker\")[\"Close\"]        .last()        .to_dict()    )    return latest_pricesdef calculate_holding_period(buy_date, sell_date):    \"\"\"    Calculate the holding period between buy and sell dates.    \"\"\"    return (sell_date - buy_date).daysdef get_applicable_tax_rate(income, holding_period, tax_rate_table):    \"\"\"    Determine the applicable tax rate based on income and holding period.    \"\"\"    for _, row in tax_rate_table.iterrows():        lower_limit = row[\"Income Range-Lower Limit\"]        upper_limit = row[\"Income Range-Upper Limit\"]        # Handle the last row with no upper limit        if pd.isna(upper_limit) or income &lt;= upper_limit:            if income &gt;= lower_limit:                return (                    row[\"Long-Term Capital Gains Tax Rate\"]                    if holding_period &gt; 365                    else row[\"Short-Term Capital Gains Tax Rate\"]                )        # If income exceeds all ranges, use the last row    last_row = tax_rate_table.iloc[-1]    return (        last_row[\"Long-Term Capital Gains Tax Rate\"]        if holding_period &gt; 365        else last_row[\"Short-Term Capital Gains Tax Rate\"]    )\n\n\n\nPortfolio Processing\n\ndef compute_fifo_portfolio_with_metrics(transactions, current_prices, customer_id):    \"\"\"    Compute FIFO portfolio with unrealized gains/losses and metrics.    \"\"\"    transactions_filtered = transactions[transactions[\"Customer ID\"] == customer_id].copy()    transactions_filtered = transactions_filtered.sort_values(by=[\"Ticker\", \"Transaction Date\"])        portfolio = []    for ticker, group in transactions_filtered.groupby(\"Ticker\"):        purchase_lots = []        remaining_quantity = 0                for _, row in group.iterrows():            if row[\"Transaction Type\"] == \"Buy\":                purchase_lots.append((row[\"Quantity\"], row[\"Price\"], row[\"Transaction Date\"]))                remaining_quantity += row[\"Quantity\"]            elif row[\"Transaction Type\"] == \"Sell\":                sell_quantity = row[\"Quantity\"]                while sell_quantity &gt; 0 and purchase_lots:                    lot_quantity, lot_price, lot_date = purchase_lots[0]                    if sell_quantity &gt;= lot_quantity:                        sell_quantity -= lot_quantity                        remaining_quantity -= lot_quantity                        purchase_lots.pop(0)                    else:                        purchase_lots[0] = (lot_quantity - sell_quantity, lot_price, lot_date)                        remaining_quantity -= sell_quantity                        sell_quantity = 0        if remaining_quantity &gt; 0:            total_cost = sum(lot[0] * lot[1] for lot in purchase_lots)            weighted_avg_price = total_cost / remaining_quantity            holding_periods = [                (lot[0] / remaining_quantity) * (datetime.now() - lot[2]).days for lot in purchase_lots            ]            avg_holding_period = sum(holding_periods)            current_price = current_prices.get(ticker, 0)            unrealized_gain_loss = (current_price - weighted_avg_price) * remaining_quantity            portfolio.append({                \"Ticker\": ticker,                \"Quantity\": remaining_quantity,                \"Purchase Price\": weighted_avg_price,                \"Current Price\": current_price,                \"Unrealized Gain/Loss\": unrealized_gain_loss,                \"Holding Period (Days)\": avg_holding_period            })    return pd.DataFrame(portfolio)\n\n\n\nTax Loss Harvesting\n\ndef identify_tlh_candidates(portfolio):    \"\"\"    Identify TLH candidates with unrealized losses.    \"\"\"    return portfolio[portfolio[\"Unrealized Gain/Loss\"] &lt; 0].sort_values(\"Unrealized Gain/Loss\")def calculate_tax_savings(tlh_candidates, income, tax_rate_table):    \"\"\"    Calculate tax savings for TLH candidates.    \"\"\"    tlh_candidates[\"Tax Rate\"] = tlh_candidates.apply(        lambda row: get_applicable_tax_rate(income, row[\"Holding Period (Days)\"], tax_rate_table),        axis=1    )    tlh_candidates[\"Tax Savings\"] = -tlh_candidates[\"Unrealized Gain/Loss\"] * tlh_candidates[\"Tax Rate\"]    return tlh_candidatesdef finalize_tlh_recommendation(tlh_candidates, realized_gains, max_loss_offset=3000):    total_offset_limit = realized_gains + max_loss_offset if realized_gains &gt; 0 else max_loss_offset    remaining_offset = total_offset_limit    tlh_candidates[\"Tax Savings per Loss\"] = tlh_candidates[\"Tax Savings\"] / abs(tlh_candidates[\"Unrealized Gain/Loss\"])    tlh_candidates = tlh_candidates.sort_values(        by=[\"Tax Savings\", \"Tax Savings per Loss\"], ascending=[False, False]    )    tlh_candidates[\"Recommended\"] = False    tlh_candidates[\"Partial Quantity\"] = 0    for i, row in tlh_candidates.iterrows():        if remaining_offset &lt;= 0:            break        # Calculate unrealized loss for the recommended quantity        unrealized_loss_per_unit = abs(row[\"Unrealized Gain/Loss\"] / row[\"Quantity\"])        max_quantity = int(remaining_offset / unrealized_loss_per_unit)        if abs(row[\"Unrealized Gain/Loss\"]) &lt;= remaining_offset:            tlh_candidates.at[i, \"Recommended\"] = True            tlh_candidates.at[i, \"Partial Quantity\"] = row[\"Quantity\"]            remaining_offset -= abs(row[\"Unrealized Gain/Loss\"])        elif max_quantity &gt; 0:            tlh_candidates.at[i, \"Recommended\"] = True            tlh_candidates.at[i, \"Partial Quantity\"] = max_quantity            remaining_offset = 0    return tlh_candidatesdef calculate_realized_gains(transactions, customer_id, tax_year):    \"\"\"    Calculate realized gains for sell transactions in a given tax year using FIFO logic.    Args:        transactions (DataFrame): Full transaction data.        customer_id (str): Customer ID for filtering.        tax_year (int): Tax year for capital gains calculation.    Returns:        float: Total realized gains for the tax year.    \"\"\"    # Filter transactions for the customer and the given tax year    transactions = transactions[transactions[\"Customer ID\"] == customer_id]    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])    sell_transactions = transactions[        (transactions[\"Transaction Type\"] == \"Sell\") &        (transactions[\"Transaction Date\"].dt.year == tax_year)    ]        # Group buy transactions for FIFO matching    buy_transactions = transactions[        (transactions[\"Transaction Type\"] == \"Buy\")    ].sort_values(by=\"Transaction Date\")    realized_gains = 0    # FIFO logic for calculating gains    for _, sell in sell_transactions.iterrows():        ticker = sell[\"Ticker\"]        quantity_to_sell = sell[\"Quantity\"]        sell_price = sell[\"Price\"]        for _, buy in buy_transactions[buy_transactions[\"Ticker\"] == ticker].iterrows():            if quantity_to_sell &lt;= 0:                break            buy_quantity = buy[\"Quantity\"]            buy_price = buy[\"Price\"]            matched_quantity = min(quantity_to_sell, buy_quantity)            realized_gains += (sell_price - buy_price) * matched_quantity            quantity_to_sell -= matched_quantity            # Adjust remaining buy quantity            buy_transactions.loc[buy.name, \"Quantity\"] -= matched_quantity    return realized_gainsdef calculate_sales_and_gains_summary(transactions, customer_id, tax_year):    \"\"\"    Calculate total sales, realized gains, percent return, and top 3 stocks by return for a given tax year using FIFO logic.    Args:        transactions (DataFrame): Full transaction data.        customer_id (str): Customer ID for filtering.        tax_year (int): Tax year for calculations.    Returns:        str: Formatted summary string with sales, realized gains, percent return, and top 3 stocks.    \"\"\"    # Filter transactions for the customer and the given tax year    transactions = transactions[transactions[\"Customer ID\"] == customer_id]    transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])    sell_transactions = transactions[        (transactions[\"Transaction Type\"] == \"Sell\") &        (transactions[\"Transaction Date\"].dt.year == tax_year)    ]    # Group buy transactions for FIFO matching    buy_transactions = transactions[        (transactions[\"Transaction Type\"] == \"Buy\")    ].sort_values(by=\"Transaction Date\")    total_sales = 0    realized_gains = 0    stock_returns = []    # FIFO logic for calculating gains    for _, sell in sell_transactions.iterrows():        ticker = sell[\"Ticker\"]        quantity_to_sell = sell[\"Quantity\"]        sell_price = sell[\"Price\"]        total_sale_for_ticker = 0        total_cost_for_ticker = 0        for _, buy in buy_transactions[buy_transactions[\"Ticker\"] == ticker].iterrows():            if quantity_to_sell &lt;= 0:                break            buy_quantity = buy[\"Quantity\"]            buy_price = buy[\"Price\"]            matched_quantity = min(quantity_to_sell, buy_quantity)            # Calculate realized gains            realized_gains += (sell_price - buy_price) * matched_quantity            # Track sales and costs for this ticker            total_sale_for_ticker += sell_price * matched_quantity            total_cost_for_ticker += buy_price * matched_quantity            quantity_to_sell -= matched_quantity            # Adjust remaining buy quantity            buy_transactions.loc[buy.name, \"Quantity\"] -= matched_quantity        # Record return for the ticker if sales occurred        if total_cost_for_ticker &gt; 0:            percent_return = ((total_sale_for_ticker - total_cost_for_ticker) / total_cost_for_ticker) * 100            stock_returns.append((ticker, percent_return, total_sale_for_ticker))        # Add to total sales        total_sales += total_sale_for_ticker    # Get top 3 stocks by return    top_3_stocks = sorted(stock_returns, key=lambda x: x[1], reverse=True)[:3]    # Calculate overall percent return    overall_percent_return = ((realized_gains / total_sales) * 100) if total_sales &gt; 0 else 0    # Build the formatted summary string    summary = f\"Total Sales Made: ${total_sales:,.2f}\\n\"    summary += f\"Realized Gains: ${realized_gains:,.2f}\\n\"    summary += f\"Overall Percent Return: {overall_percent_return:.2f}%\\n\"    summary += \"Top 3 Stocks by Return:\\n\"    for ticker, percent_return, total_sales in top_3_stocks:        summary += f\"  {ticker}: {percent_return:.2f}% return, Total Sales: ${total_sales:,.2f}\\n\"    return summary\n\n\n\nWash Sale Detection\n\ndef detect_wash_sales(transactions, tlh_candidates):    \"\"\"    Detect wash sale violations for TLH candidates and provide detailed warnings.    Args:        transactions (DataFrame): Transaction data containing all trades.        tlh_candidates (DataFrame): TLH candidates being evaluated.    Returns:        Tuple: (List of detailed warnings, List of tickers with wash-sale violations)    \"\"\"    warnings = []    wash_sale_tickers = []  # To store tickers with wash sale warnings    for _, row in tlh_candidates.iterrows():        ticker = row[\"Ticker\"]        sale_date = datetime.now()  # Assume current date for sale        # Filter transactions for recent buys within the last 30 days        recent_buys = transactions[            (transactions[\"Ticker\"] == ticker) &            (transactions[\"Transaction Type\"] == \"Buy\") &            (transactions[\"Transaction Date\"] &gt;= sale_date - timedelta(days=30))        ]        if not recent_buys.empty:            # Find the most recent purchase date            most_recent_buy_date = recent_buys[\"Transaction Date\"].max()            safe_sell_date = most_recent_buy_date + timedelta(days=31)            warnings.append(                f\"Wash sale warning: Recent buy detected for {ticker} on {most_recent_buy_date.date()}. \"                f\"You can safely sell after {safe_sell_date.date()} to avoid violations.\"            )            wash_sale_tickers.append(ticker)  # Add ticker to the list    return warnings, wash_sale_tickers\n\n\n\nReinvestment Recommendation System\n\ndef identify_stocks_to_sell(portfolio, customer_preferences):    \"\"\"    Identify stocks to sell based on risk tolerance, sectors, and investment goals.    \"\"\"    # Extract preferences    risk_tolerance = customer_preferences[\"Risk Tolerance\"]    preferred_sectors = customer_preferences[\"Preferred Sectors\"]    # Convert sectors to a list if it's a string    if isinstance(preferred_sectors, str):        preferred_sectors = [sector.strip() for sector in preferred_sectors.split(\",\")]    # Filter based on risk tolerance    if risk_tolerance == \"Low\":        portfolio = portfolio[portfolio[\"Beta\"] &lt; 1]    elif risk_tolerance == \"Moderate\":        portfolio = portfolio[(portfolio[\"Beta\"] &gt;= 1) & (portfolio[\"Beta\"] &lt;= 1.5)]    elif risk_tolerance == \"High\":        portfolio = portfolio[portfolio[\"Beta\"] &gt; 1.5]    # Filter non-preferred sectors    portfolio = portfolio[~portfolio[\"Sector\"].isin(preferred_sectors)]    return portfoliodef recommend_reinvestment_stocks_with_details(available_balance, stock_data, wash_sale_tickers, customer_preferences, max_stock_allocation_pct=0.15, max_sector_allocation_pct=0.30):    \"\"\"    Recommend stocks for reinvestment while providing detailed information like purchase quantity, current price, YTD returns, and other metrics.    \"\"\"    latest_prices = get_latest_prices(historical_prices)    latest_prices = pd.DataFrame.from_dict(latest_prices, orient=\"index\", columns=[\"Current Price\"]).reset_index().rename(columns={\"index\": \"Ticker\"})    stock_data = stock_data.merge(latest_prices, on=\"Ticker\", how=\"left\")    # Exclude wash-sale-triggering stocks    stock_data = stock_data[~stock_data[\"Ticker\"].isin(wash_sale_tickers)]        stock_data = stock_data[stock_data[\"YTD Return (%)\"] &gt; 0]    # Convert preferred sectors to a list if it's a string    preferred_sectors = customer_preferences[\"Preferred Sectors\"]    if isinstance(preferred_sectors, str):        preferred_sectors = [sector.strip() for sector in preferred_sectors.split(\",\")]    # Filter by sector preference    stock_data = stock_data[stock_data[\"Sector\"].isin(preferred_sectors)]    # Filter by risk tolerance    risk_tolerance = customer_preferences[\"Risk Tolerance\"]    if risk_tolerance == \"Low\":        stock_data = stock_data[stock_data[\"Beta\"] &lt; 1]    elif risk_tolerance == \"Moderate\":        stock_data = stock_data[(stock_data[\"Beta\"] &gt;= 1) & (stock_data[\"Beta\"] &lt;= 1.5)]    elif risk_tolerance == \"High\":        stock_data = stock_data[stock_data[\"Beta\"] &gt; 1.5]    # Rank stocks by customer goals    if customer_preferences[\"Investment Goals\"] == \"Dividend Income\":        stock_data = stock_data.sort_values(by=\"Dividend Yield (%)\", ascending=False)    elif customer_preferences[\"Investment Goals\"] == \"Growth\":        stock_data = stock_data.sort_values(by=\"Growth Rate\", ascending=False)    # Allocation logic    allocation = []    sector_allocations = {}    for _, row in stock_data.iterrows():        # Calculate max allocations        max_stock_allocation = available_balance * max_stock_allocation_pct        max_sector_allocation = available_balance * max_sector_allocation_pct        # Get current sector allocation        current_sector_allocation = sector_allocations.get(row[\"Sector\"], 0)        remaining_sector_allocation = max_sector_allocation - current_sector_allocation        # Allocate funds while respecting constraints        allocation_amount = min(max_stock_allocation, remaining_sector_allocation, available_balance)        if allocation_amount &gt; 0:            # Calculate purchase quantity            purchase_quantity = allocation_amount // row[\"Current Price\"]            allocation_amount = purchase_quantity * row[\"Current Price\"]  # Recalculate based on whole shares            allocation.append({                \"Ticker\": row[\"Ticker\"],                \"Allocation\": allocation_amount,                \"Purchase Quantity\": purchase_quantity,                \"Current Price\": row[\"Current Price\"],                \"YTD Return\": row[\"YTD Return (%)\"],                \"P/E Ratio\": row.get(\"P/E Ratio\", \"N/A\"),                \"Market Cap (B)\": row.get(\"Market Cap (B)\", \"N/A\"),                \"Beta\": row.get(\"Beta\", \"N/A\"),                \"52-Week High\": row.get(\"52-Week High\", \"N/A\"),                \"52-Week Low\": row.get(\"52-Week Low\", \"N/A\"),                \"Growth Rate\": row.get(\"Growth Rate\",\"N/A\"),                \"Projected Growth\": allocation_amount * (1 + row[\"Growth Rate\"])            })            # Update balances            available_balance -= allocation_amount            sector_allocations[row[\"Sector\"]] = current_sector_allocation + allocation_amount        # Stop if all funds are allocated        if available_balance &lt;= 0:            break    # Redistribute residual balance proportionally if any remains    if available_balance &gt; 0:        total_allocation = sum(a[\"Allocation\"] for a in allocation)        for entry in allocation:            proportional_addition = (entry[\"Allocation\"] / total_allocation) * available_balance            entry[\"Allocation\"] += proportional_addition            entry[\"Purchase Quantity\"] += int(proportional_addition // entry[\"Current Price\"])            entry[\"Projected Growth\"] = entry[\"Allocation\"] * (1 + stock_data.loc[stock_data[\"Ticker\"] == entry[\"Ticker\"], \"Growth Rate\"].values[0])        # Filter out zero-allocation stocks    allocation_df = pd.DataFrame(allocation)    allocation_df = allocation_df[allocation_df[\"Allocation\"] &gt; 0]    allocation_df = allocation_df.drop(columns=[\"Allocation\"], errors=\"ignore\")    return allocation_df\n\n\n\nExecute code and Convert all data to JSON for Watsonx Discovery\n\nimport pandas as pdimport jsonimport re# Assume all necessary modules and functions are already imported# and original_transactions, customer_profiles, historical_prices,# tax_rates, stock_expanded_data, etc., are already defined.all_customers_data = []# Function to reset data before processing each customerdef reset_data():    global transactions    transactions = original_transactions.copy()    # Repeat for other DataFrames if necessary# Function to process a single customerdef process_customer(customer_id):    # Reset data before processing each customer    reset_data()        tax_year = 2024  # Use the current or target tax year    # Extract the customer's profile    customer_profile = customer_profiles[customer_profiles[\"Customer ID\"] == customer_id].iloc[0]        # Extract user preferences    risk_tolerance = customer_profile[\"Risk Tolerance\"]    preferred_sectors = customer_profile[\"Preferred Sectors\"].split(\", \")    investment_goals = customer_profile[\"Investment Goals\"]    current_prices = get_latest_prices(historical_prices)    income = customer_profile[\"Annual Income\"]        # Calculate the customer's portfolio    portfolio = compute_fifo_portfolio_with_metrics(transactions, current_prices, customer_id)        # Identify TLH candidates    tlh_candidates = identify_tlh_candidates(portfolio)        # Calculate tax savings for TLH candidates    tlh_candidates_with_savings = calculate_tax_savings(tlh_candidates, income, tax_rates)        # Calculate realized gains dynamically from transactions    realized_gains = calculate_realized_gains(transactions, customer_id, tax_year)        # Generate final TLH recommendations    final_tlh_recommendations = finalize_tlh_recommendation(        tlh_candidates_with_savings,        realized_gains,        max_loss_offset=3000    )        # Detect potential wash sale violations    wash_sale_warnings, wash_sale_tickers = detect_wash_sales(transactions, tlh_candidates_with_savings)        # Calculate the sale proceeds for reinvestment    final_tlh_recommendations[\"Sale Proceeds\"] = (        final_tlh_recommendations[\"Partial Quantity\"] * final_tlh_recommendations[\"Current Price\"]    )    available_balance = final_tlh_recommendations[\"Sale Proceeds\"].sum()        # Identify stocks to sell (if applicable)    # stocks_to_sell = identify_stocks_to_sell(stock_expanded_data, customer_profile)        # Filter stocks based on customer preferences    recommended_stocks = recommend_reinvestment_stocks_with_details(        available_balance, stock_expanded_data, wash_sale_tickers, customer_profile    )        # --- Portfolio Summary ---    portfolio_updated = portfolio.drop(columns=[\"Holding Period (Days)\"])    going_well = portfolio_updated[portfolio_updated[\"Unrealized Gain/Loss\"] &gt; 0]        going_bad = portfolio_updated[portfolio_updated[\"Unrealized Gain/Loss\"] &lt; 0].copy()    going_bad['Unrealized Gain/Loss'] = going_bad['Unrealized Gain/Loss'].abs()    going_bad.rename(columns={'Unrealized Gain/Loss':'Unrealized Loss'}, inplace=True)    going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)        # Calculate Total Investments    portfolio[\"Initial Investment\"] = portfolio[\"Purchase Price\"] * portfolio[\"Quantity\"]    portfolio[\"Current Value\"] = portfolio[\"Current Price\"] * portfolio[\"Quantity\"]    total_initial_investment = portfolio[\"Initial Investment\"].sum()    total_current_value = portfolio[\"Current Value\"].sum()    net_unrealized_gain_loss_percent = (        (portfolio[\"Unrealized Gain/Loss\"].sum() / portfolio[\"Initial Investment\"].sum()) * 100    ).round(2)        # Sales made in the tax year    customer_transactions = transactions[transactions[\"Customer ID\"] == customer_id].copy()    customer_transactions[\"Transaction Date\"] = pd.to_datetime(customer_transactions[\"Transaction Date\"])    sell_transactions = customer_transactions[        (customer_transactions[\"Transaction Type\"] == \"Sell\") &        (customer_transactions[\"Transaction Date\"].dt.year == tax_year)    ]        # Calculate sales and gains summary    summary = calculate_sales_and_gains_summary(transactions, customer_id, tax_year)    total_sales = re.search(r\"Total Sales Made: \\$(\\d[\\d,\\.]*)\", summary).group(1)    realized_gains_str = re.search(r\"Realized Gains: \\$(\\d[\\d,\\.]*)\", summary).group(1)    overall_percent_return = re.search(r\"Overall Percent Return: ([\\d\\.]*)%\", summary).group(1)    top_stocks = re.findall(r\"(\\w+): ([\\d\\.]+)% return, Total Sales: \\$(\\d[\\d,\\.]*)\", summary)    realized_gains_float = float(realized_gains_str.replace(\",\", \"\")) if isinstance(realized_gains_str, str) else float(realized_gains_str)        # --- Tax Loss Harvesting Analysis ---    # Generate TLH Table with Additional Columns    tlh_table = final_tlh_recommendations[[        \"Ticker\", \"Unrealized Gain/Loss\", \"Partial Quantity\", \"Current Price\", \"Recommended\", \"Sale Proceeds\"    ]].copy()        # Calculate Absolute Losses    tlh_table[\"Unrealized Gain/Loss\"] = tlh_table[\"Unrealized Gain/Loss\"].abs()    tlh_table.rename(columns={        \"Unrealized Gain/Loss\": \"Losses\",        \"Partial Quantity\": \"Quantity to Sell\"    }, inplace=True)        # Calculate Total Tax Savings    total_tax_savings = final_tlh_recommendations[final_tlh_recommendations[\"Recommended\"]][\"Tax Savings\"].sum()        # Calculate Total Sale Proceeds from TLH Sales    total_sale_proceeds = final_tlh_recommendations[final_tlh_recommendations[\"Recommended\"]][\"Sale Proceeds\"].sum()        # Generate Wash Sale Output    wash_sale_output = \"\\n\".join(wash_sale_warnings) if wash_sale_warnings else \"No wash sale warnings.\"        # Calculate Total Offset Limit    total_offset_limit = realized_gains_float + 3000 if realized_gains_float &gt; 0 else 3000        # --- Reinvestment Recommendations ---    # Reinvest amount    total_investment = (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Current Price\"]).sum()        # Add Allocation (%) column    recommended_stocks[\"Allocation (%)\"] = (        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Current Price\"]) / total_investment * 100    )        # Calculate Weighted YTD Return    weighted_ytd_return = (        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"YTD Return\"]).sum() /        recommended_stocks[\"Purchase Quantity\"].sum()    )        # Calculate Portfolio Beta    portfolio_beta = (        (recommended_stocks[\"Purchase Quantity\"] * recommended_stocks[\"Beta\"]).sum() /        recommended_stocks[\"Purchase Quantity\"].sum()    )        # Calculate Average P/E Ratio    average_pe_ratio = recommended_stocks[\"P/E Ratio\"].mean()        # Calculate Average Growth Rate    average_growth_rate = recommended_stocks[\"Growth Rate\"].mean()        # Create the Recommendations Table    recommendations_table = recommended_stocks[        [\"Ticker\", \"Purchase Quantity\", \"Current Price\", \"YTD Return\", \"Beta\", \"P/E Ratio\", \"Growth Rate\", \"Allocation (%)\"]    ].copy()        # Round numbers where needed    recommendations_table[\"Allocation (%)\"] = recommendations_table[\"Allocation (%)\"].round(2)    weighted_ytd_return = round(weighted_ytd_return, 2)    portfolio_beta = round(portfolio_beta, 2)    average_pe_ratio = round(average_pe_ratio, 2)    average_growth_rate = round(average_growth_rate, 2)    recommendations_table[\"YTD Return\"] = recommendations_table[\"YTD Return\"].round(2)    recommendations_table[\"Growth Rate\"] = recommendations_table[\"Growth Rate\"].round(2)    recommendations_table[\"Current Price\"] = recommendations_table[\"Current Price\"].round(2)    recommendations_table[\"P/E Ratio\"] = recommendations_table[\"P/E Ratio\"].round(2)    recommendations_table[\"Beta\"] = recommendations_table[\"Beta\"].round(2)        # --- Executive Summary ---    net_unrealized_gain_loss = portfolio[\"Unrealized Gain/Loss\"].sum().round(2)    recommendations_stocks = recommended_stocks[\"Ticker\"]    expected_average_growth_rate = average_growth_rate        # --- Convert all data to JSON ---    output_data = {        \"Customer ID\": customer_id,        \"Executive Summary\": {            \"Customer Profile\": {                \"Risk Tolerance\": customer_profile[\"Risk Tolerance\"],                \"Preferred Sectors\": customer_profile[\"Preferred Sectors\"],                \"Investment Goals\": customer_profile[\"Investment Goals\"],            },            \"Portfolio Summary\": {                \"Total Current Value\": round(total_current_value, 2),                \"Net Unrealized Gain/Loss\": round(net_unrealized_gain_loss, 2),            },            \"Tax-Loss Harvesting\": {                \"Total Tax Savings\": round(total_tax_savings, 2),                \"Reinvestment Amount\": round(total_sale_proceeds, 2),            },            \"Reinvestment Recommendations\": {                \"Recommended Stocks\": recommendations_stocks.tolist(),                \"Expected Average Growth Rate %\": round(expected_average_growth_rate, 2),            },        },        \"Portfolio Summary\": {            \"Total Initial Investment\": round(total_initial_investment, 2),            \"Total Current Value\": round(total_current_value, 2),            \"Net Unrealized Gain/Loss Percent\": round(net_unrealized_gain_loss_percent, 2),            \"Going Bad Investments\": [                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}            for record in going_bad.to_dict(orient=\"records\")            ],            \"Going Well Investments\": [                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}            for record in going_well.to_dict(orient=\"records\")            ],            \"Sales Analysis\": {                \"Total Sales Made\": round(float(total_sales.replace(\",\", \"\")), 2),                \"Realized Gains\": round(realized_gains_float, 2),                \"Overall Percent Return\": round(float(overall_percent_return), 2),                \"Top Stocks by Return\": [                    {                        \"Ticker\": stock[0],                        \"Return Percent\": round(float(stock[1]), 2),                        \"Total Sales\": round(float(stock[2].replace(\",\", \"\")), 2),                    }                    for stock in top_stocks                ],            },        },        \"Tax Loss Harvesting Analysis\": {            \"Table\": [                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}            for record in tlh_table.to_dict(orient=\"records\")            ],            \"Total Tax Savings\": round(total_tax_savings, 2),            \"Total Sale Proceeds from TLH Sales\": round(total_sale_proceeds, 2),            \"Wash Sale Warnings\": wash_sale_warnings,        },        \"Reinvestment Recommendations\": {            \"Customer Profile\": {                \"Risk Tolerance\": customer_profile[\"Risk Tolerance\"],                \"Preferred Sectors\": customer_profile[\"Preferred Sectors\"],                \"Investment Goals\": customer_profile[\"Investment Goals\"],            },            \"Table\": [                {k: round(v, 2) if isinstance(v, (int, float)) else v for k, v in record.items()}            for record in recommendations_table.to_dict(orient=\"records\")            ],            \"New Portfolio Summary\": {                \"Total Investment\": round(total_investment, 2),                \"Weighted YTD Return\": weighted_ytd_return,                \"Portfolio Beta\": portfolio_beta,                \"Average P/E Ratio\": average_pe_ratio,                \"Expected Average Growth Rate\": average_growth_rate,            },        },    }        # Instead of writing to a file, append the output_data to the list    all_customers_data.append(output_data)        print(f\"Processed customer {customer_id}\")# Get a list of all customer IDscustomer_ids = customer_profiles[\"Customer ID\"].unique()# Loop over all customer IDs and process each onefor customer_id in customer_ids:    process_customer(customer_id)# After processing all customers, write the accumulated data to a single JSON filewith open(\"all_customers_report.json\", \"w\") as file:    json.dump(all_customers_data, file, indent=4)print(\"All customer data has been written to 'all_customers_report.json'\")\n\nProcessed customer C001\nProcessed customer C002\nAll customer data has been written to 'all_customers_report.json'\n\n\n/tmp/wsuser/ipykernel_438/2890460161.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/3882620736.py:77: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)\n/tmp/wsuser/ipykernel_438/2890460161.py:112: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/2890460161.py:63: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n/tmp/wsuser/ipykernel_438/3882620736.py:77: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  going_well.rename(columns={'Unrealized Gain/Loss':'Unrealized Gain'}, inplace=True)\n/tmp/wsuser/ipykernel_438/2890460161.py:112: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  transactions[\"Transaction Date\"] = pd.to_datetime(transactions[\"Transaction Date\"])\n\n\n\nimport jsonimport ibm_boto3from ibm_botocore.client import Config# IBM COS Credentials and ConfigurationsCOS_API_KEY = \"RuSq2hb5DI8kOl1ZznOxQHx3igYJObJF-yTHDDkNi55E\"  # Replace with your IBM COS API KeyCOS_ENDPOINT = \"https://s3.direct.us-south.cloud-object-storage.appdomain.cloud\"  # Replace with your endpointCOS_BUCKET_NAME = \"007tlhdata\"  # Replace with your bucket nameCOS_OBJECT_NAME = \"json_customer_data/all_customers_data.json\"  # Name of the file to be saved in COS# Initialize COS clientcos_client = ibm_boto3.client(    service_name=\"s3\",    ibm_api_key_id=COS_API_KEY,    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",    config=Config(signature_version=\"oauth\"),    endpoint_url=COS_ENDPOINT,)# Convert JSON to a stringjson_data = json.dumps(all_customers_data)# Upload the JSON file to IBM COStry:    response = cos_client.put_object(        Bucket=COS_BUCKET_NAME,        Key=COS_OBJECT_NAME,        Body=json_data,        ContentType=\"application/json\",    )    print(f\"Upload Successful! ETag: {response['ETag']}\")except Exception as e:    print(f\"Error uploading file: {e}\")\n\nUpload Successful! ETag: \"1abb7028705e029d39029b84725f09f8\""
  },
  {
    "objectID": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:Data_Collection_AP__wcZXQ.html",
    "href": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:Data_Collection_AP__wcZXQ.html",
    "title": "007 AI Financial Advisor",
    "section": "",
    "text": "import yfinance as yf\nimport pandas as pd\nfrom datetime import datetime\n\ndef fetch_data(tickers, start_date, end_date):\n    \"\"\"\n    Fetch historical price data and sector/industry classification for a list of tickers.\n\n    Parameters:\n        tickers (list): List of stock tickers.\n        start_date (str): Start date in 'YYYY-MM-DD' format.\n        end_date (str): End date in 'YYYY-MM-DD' format.\n\n    Returns:\n        tuple:\n            - historical_prices (pd.DataFrame): Historical price data for all tickers.\n            - sector_data (pd.DataFrame): Sector and industry classification for all tickers.\n    \"\"\"\n    historical_prices = pd.DataFrame()\n    \n\n    for ticker in tickers:\n        try:\n            print(f\"Fetching data for {ticker}...\")\n            stock = yf.Ticker(ticker)\n\n            # Fetch historical price data\n            history = stock.history(start=start_date, end=end_date)\n            history['Ticker'] = ticker\n            historical_prices = pd.concat([historical_prices, history])\n\n        except Exception as e:\n            print(f\"Error fetching data for {ticker}: {e}\")\n\n\n\n    return historical_prices\n\n\n# Full ticker list\ntickers = [\n    \"AAPL\", \"MSFT\", \"GOOGL\", \"NVDA\", \"META\", \"AMD\", \"CRM\", \"ORCL\", \"ADBE\", \"INTC\", \"TSLA\", \"XOM\", \"CVX\", \"ENPH\", \"FSLR\", \"NEE\", \"RUN\", \"SEDG\", \"BP\", \"SLB\", \"COP\", \"EOG\", \"JPM\", \"BAC\", \"GS\", \"WFC\", \"MS\", \"BLK\", \"JNJ\", \"PFE\", \"MRK\", \"ABBV\", \"AMGN\", \"UNH\", \"DIS\", \"HD\", \"AMZN\", \"NKE\", \"MCD\", \"SBUX\", \"BA\", \"CAT\", \"GE\", \"DE\", \"MMM\", \"PG\", \"KO\", \"PEP\", \"WMT\", \"COST\", \"AMT\", \"PLD\", \"SPG\", \"O\", \"DUK\", \"SO\", \"AWK\", \"GOOG\", \"NFLX\", \"T\", \"NEM\", \"BHP\", \"RIO\", \"LIN\", \"SPY\", \"QQQ\", \"DIA\", \"IVV\", \"VTI\", \"ARKK\", \"VOO\", \"XLK\", \"XLE\", \"IHI\", \"IYR\"\n]\n\n# Define date range\nstart_date = \"2023-01-01\"\nend_date = datetime.today().strftime('%Y-%m-%d')\n\n# Fetch data\nhistorical_prices = fetch_data(tickers, start_date, end_date)\n\n\n# Display summary\nprint(\"\\nHistorical Prices (Sample):\")\nprint(historical_prices.head())\n\nFetching data for AAPL...\nFetching data for MSFT...\nFetching data for GOOGL...\nFetching data for NVDA...\nFetching data for META...\nFetching data for AMD...\nFetching data for CRM...\nFetching data for ORCL...\nFetching data for ADBE...\nFetching data for INTC...\nFetching data for TSLA...\nFetching data for XOM...\nFetching data for CVX...\nFetching data for ENPH...\nFetching data for FSLR...\nFetching data for NEE...\nFetching data for RUN...\nFetching data for SEDG...\nFetching data for BP...\nFetching data for SLB...\nFetching data for COP...\nFetching data for EOG...\nFetching data for JPM...\nFetching data for BAC...\nFetching data for GS...\nFetching data for WFC...\nFetching data for MS...\nFetching data for BLK...\nFetching data for JNJ...\nFetching data for PFE...\nFetching data for MRK...\nFetching data for ABBV...\nFetching data for AMGN...\nFetching data for UNH...\nFetching data for DIS...\nFetching data for HD...\nFetching data for AMZN...\nFetching data for NKE...\nFetching data for MCD...\nFetching data for SBUX...\nFetching data for BA...\nFetching data for CAT...\nFetching data for GE...\nFetching data for DE...\nFetching data for MMM...\nFetching data for PG...\nFetching data for KO...\nFetching data for PEP...\nFetching data for WMT...\nFetching data for COST...\nFetching data for AMT...\nFetching data for PLD...\nFetching data for SPG...\nFetching data for O...\nFetching data for DUK...\nFetching data for SO...\nFetching data for AWK...\nFetching data for GOOG...\nFetching data for NFLX...\nFetching data for T...\nFetching data for NEM...\nFetching data for BHP...\nFetching data for RIO...\nFetching data for LIN...\nFetching data for SPY...\nFetching data for QQQ...\nFetching data for DIA...\nFetching data for IVV...\nFetching data for VTI...\nFetching data for ARKK...\nFetching data for VOO...\nFetching data for XLK...\nFetching data for XLE...\nFetching data for IHI...\nFetching data for IYR...\n\nHistorical Prices (Sample):\n                                 Open        High         Low       Close  \\\nDate                                                                        \n2023-01-03 00:00:00-05:00  128.924237  129.537780  122.877820  123.768456   \n2023-01-04 00:00:00-05:00  125.569520  127.321104  123.778358  125.045036   \n2023-01-05 00:00:00-05:00  125.807014  126.440353  123.461682  123.718971   \n2023-01-06 00:00:00-05:00  124.698677  128.934129  123.590330  128.271103   \n2023-01-09 00:00:00-05:00  129.112255  132.021662  128.538289  128.795578   \n\n                              Volume  Dividends  Stock Splits Ticker  \\\nDate                                                                   \n2023-01-03 00:00:00-05:00  112117500        0.0           0.0   AAPL   \n2023-01-04 00:00:00-05:00   89113600        0.0           0.0   AAPL   \n2023-01-05 00:00:00-05:00   80962700        0.0           0.0   AAPL   \n2023-01-06 00:00:00-05:00   87754700        0.0           0.0   AAPL   \n2023-01-09 00:00:00-05:00   70790800        0.0           0.0   AAPL   \n\n                           Capital Gains  \nDate                                      \n2023-01-03 00:00:00-05:00            NaN  \n2023-01-04 00:00:00-05:00            NaN  \n2023-01-05 00:00:00-05:00            NaN  \n2023-01-06 00:00:00-05:00            NaN  \n2023-01-09 00:00:00-05:00            NaN  \n\n\n\nhistorical_price\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nDividends\nStock Splits\nTicker\nCapital Gains\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023-01-03 00:00:00-05:00\n128.924245\n129.537788\n122.877827\n123.768463\n112117500\n0.0\n0.0\nAAPL\nNaN\n\n\n2023-01-04 00:00:00-05:00\n125.569527\n127.321112\n123.778365\n125.045044\n89113600\n0.0\n0.0\nAAPL\nNaN\n\n\n2023-01-05 00:00:00-05:00\n125.807022\n126.440361\n123.461690\n123.718979\n80962700\n0.0\n0.0\nAAPL\nNaN\n\n\n2023-01-06 00:00:00-05:00\n124.698692\n128.934144\n123.590345\n128.271118\n87754700\n0.0\n0.0\nAAPL\nNaN\n\n\n2023-01-09 00:00:00-05:00\n129.112286\n132.021694\n128.538320\n128.795609\n70790800\n0.0\n0.0\nAAPL\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2024-11-13 00:00:00-05:00\n99.010002\n99.410004\n98.430000\n98.559998\n4801500\n0.0\n0.0\nIYR\n0.0\n\n\n2024-11-14 00:00:00-05:00\n98.540001\n98.540001\n97.559998\n97.690002\n6714800\n0.0\n0.0\nIYR\n0.0\n\n\n2024-11-15 00:00:00-05:00\n97.260002\n97.989998\n96.959999\n97.800003\n6786300\n0.0\n0.0\nIYR\n0.0\n\n\n2024-11-18 00:00:00-05:00\n97.389999\n98.620003\n97.180000\n98.599998\n4726100\n0.0\n0.0\nIYR\n0.0\n\n\n2024-11-19 00:00:00-05:00\n98.300003\n99.320000\n97.889999\n99.120003\n5340800\n0.0\n0.0\nIYR\n0.0\n\n\n\n\n35550 rows × 9 columns\n\n\n\n\nhistorical_prices.to_csv(\"/Users/nitikabhatia/Downloads/latest_historical_prices.csv\")\n\n\n!pip install yahooquery\n\nCollecting yahooquery\n  Obtaining dependency information for yahooquery from https://files.pythonhosted.org/packages/d1/a9/9a06f31cc068c7997b63a358f94ed433afb28599ef63bdcd5333db4a19d8/yahooquery-2.3.7-py3-none-any.whl.metadata\n  Downloading yahooquery-2.3.7-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: beautifulsoup4&lt;5.0.0,&gt;=4.12.2 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from yahooquery) (4.12.2)\nRequirement already satisfied: lxml&lt;5.0.0,&gt;=4.9.3 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from yahooquery) (4.9.3)\nRequirement already satisfied: pandas&lt;3.0.0,&gt;=2.0.3 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from yahooquery) (2.1.4)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.31.0 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from yahooquery) (2.31.0)\nCollecting requests-futures&lt;2.0.0,&gt;=1.0.1 (from yahooquery)\n  Obtaining dependency information for requests-futures&lt;2.0.0,&gt;=1.0.1 from https://files.pythonhosted.org/packages/91/23/7c1096731c15c83826cb0dd42078b561a838aed44c36f370aeb815168106/requests_futures-1.0.2-py2.py3-none-any.whl.metadata\n  Downloading requests_futures-1.0.2-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.65.0 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from yahooquery) (4.65.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from beautifulsoup4&lt;5.0.0,&gt;=4.12.2-&gt;yahooquery) (2.4)\nRequirement already satisfied: numpy&lt;2,&gt;=1.23.2 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from pandas&lt;3.0.0,&gt;=2.0.3-&gt;yahooquery) (1.24.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from pandas&lt;3.0.0,&gt;=2.0.3-&gt;yahooquery) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from pandas&lt;3.0.0,&gt;=2.0.3-&gt;yahooquery) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from pandas&lt;3.0.0,&gt;=2.0.3-&gt;yahooquery) (2023.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from requests&lt;3.0.0,&gt;=2.31.0-&gt;yahooquery) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from requests&lt;3.0.0,&gt;=2.31.0-&gt;yahooquery) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from requests&lt;3.0.0,&gt;=2.31.0-&gt;yahooquery) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from requests&lt;3.0.0,&gt;=2.31.0-&gt;yahooquery) (2024.6.2)\nRequirement already satisfied: six&gt;=1.5 in /Users/nitikabhatia/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&lt;3.0.0,&gt;=2.0.3-&gt;yahooquery) (1.16.0)\nDownloading yahooquery-2.3.7-py3-none-any.whl (52 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.7/52.7 kB 7.0 MB/s eta 0:00:00\nDownloading requests_futures-1.0.2-py2.py3-none-any.whl (7.7 kB)\nInstalling collected packages: requests-futures, yahooquery\nSuccessfully installed requests-futures-1.0.2 yahooquery-2.3.7\n\n\n\nimport yfinance as yf\nimport pandas as pd\nfrom datetime import datetime\n\ndef fetch_stock_data_with_ytd(stock_tickers):\n    \"\"\"\n    Fetch enhanced stock data with calculated YTD Return.\n    \"\"\"\n    stock_data = []\n    current_year = datetime.now().year\n\n    for ticker in stock_tickers:\n        try:\n            stock = yf.Ticker(ticker)\n            info = stock.info\n            \n            # Retrieve historical data to calculate YTD return\n            hist = stock.history(start=f\"{current_year}-01-01\", end=datetime.now().strftime('%Y-%m-%d'))\n            if not hist.empty:\n                jan_1_price = hist.iloc[0][\"Close\"]\n                current_price = hist.iloc[-1][\"Close\"]\n                ytd_return = ((current_price - jan_1_price) / jan_1_price) * 100\n            else:\n                ytd_return = \"N/A\"\n            \n            # Extract key metrics\n            stock_details = {\n                \"Ticker\": ticker,\n                \"Sector\": info.get(\"sector\", \"N/A\"),\n                \"Beta\": info.get(\"beta\", \"N/A\"),\n                \"Dividend Yield (%)\": info.get(\"dividendYield\", \"N/A\") * 100 if info.get(\"dividendYield\") else \"N/A\",\n                \"Growth Rate\": info.get(\"earningsGrowth\", \"N/A\"),\n                \"EPS\": info.get(\"trailingEps\", \"N/A\"),\n                \"P/E Ratio\": info.get(\"trailingPE\", \"N/A\"),\n                \"P/B Ratio\": info.get(\"priceToBook\", \"N/A\"),\n                \"Market Cap (B)\": info.get(\"marketCap\", 0) / 1e9,\n                \"Volume\": info.get(\"volume\", \"N/A\"),\n                \"52-Week High\": info.get(\"fiftyTwoWeekHigh\", \"N/A\"),\n                \"52-Week Low\": info.get(\"fiftyTwoWeekLow\", \"N/A\"),\n                \"YTD Return (%)\": ytd_return,\n            }\n\n            stock_data.append(stock_details)\n\n        except Exception as e:\n            print(f\"Error fetching data for {ticker}: {e}\")\n            continue\n\n    return pd.DataFrame(stock_data)\n\nstock_tickers = [\n    \"AAPL\", \"MSFT\", \"GOOGL\", \"NVDA\", \"META\", \"AMD\", \"CRM\", \"ORCL\", \"ADBE\", \"INTC\", \"TSLA\", \"XOM\", \"CVX\", \"ENPH\", \"FSLR\", \"NEE\", \"RUN\", \"SEDG\", \"BP\", \"SLB\", \"COP\", \"EOG\", \"JPM\", \"BAC\", \"GS\", \"WFC\", \"MS\", \"BLK\", \"JNJ\", \"PFE\", \"MRK\", \"ABBV\", \"AMGN\", \"UNH\", \"DIS\", \"HD\", \"AMZN\", \"NKE\", \"MCD\", \"SBUX\", \"BA\", \"CAT\", \"GE\", \"DE\", \"MMM\", \"PG\", \"KO\", \"PEP\", \"WMT\", \"COST\", \"AMT\", \"PLD\", \"SPG\", \"O\", \"DUK\", \"SO\", \"AWK\", \"GOOG\", \"NFLX\", \"T\", \"NEM\", \"BHP\", \"RIO\", \"LIN\"\n]\n\n\n\nstock_data = fetch_stock_data_with_ytd(stock_tickers)\n\n# Display the fetched stock data\nprint(stock_data)\n\n   Ticker                  Sector   Beta Dividend Yield (%) Growth Rate  \\\n0    AAPL              Technology  1.240               0.44      -0.341   \n1    MSFT              Technology  0.904               0.79       0.104   \n2   GOOGL  Communication Services  1.034               0.45       0.366   \n3    NVDA              Technology  1.657               0.03        1.68   \n4    META  Communication Services  1.215               0.36       0.374   \n..    ...                     ...    ...                ...         ...   \n59      T  Communication Services  0.730               4.88         N/A   \n60    NEM         Basic Materials  0.531               2.32       3.039   \n61    BHP         Basic Materials  0.859               5.59       0.077   \n62    RIO         Basic Materials  0.617               6.97       0.133   \n63    LIN         Basic Materials  0.949               1.25       0.009   \n\n      EPS  P/E Ratio  P/B Ratio  Market Cap (B)     Volume  52-Week High  \\\n0    6.09  37.602627   60.79108     3461.518197   30174153        237.49   \n1   12.12  34.281353  10.738117     3089.118265   18442663        468.35   \n2    7.44  23.653225   6.870729     2188.452037   18962205        191.75   \n3    2.12   68.81604   61.60895     3606.152741  260171855        149.77   \n4   21.38  26.450891   8.675483     1416.463647    9566484        602.95   \n..    ...        ...        ...             ...        ...           ...   \n59   1.24   18.41129   1.600308      163.811869   13924052         23.20   \n60  -2.18        N/A   1.655244       49.158210    6408011         58.72   \n61   3.11  16.807076   5.914234      132.929937    1811485         69.11   \n62   6.59   9.467375   1.832305       99.642450    1206041         75.09   \n63  13.37  33.667915   5.471563      214.337782    1828508        487.49   \n\n    52-Week Low  YTD Return (%)  \n0        164.08       23.571612  \n1        362.90       13.267011  \n2        127.90       29.232873  \n3         45.01      205.268110  \n4        313.66       62.516795  \n..          ...             ...  \n59        15.94       39.927917  \n60        29.42        7.541056  \n61        50.90      -18.216277  \n62        59.35       -9.906014  \n63       396.07        9.408891  \n\n[64 rows x 13 columns]\n\n\n\nstock_data\n\n\n\n\n\n\n\n\nTicker\nSector\nBeta\nDividend Yield (%)\nGrowth Rate\nEPS\nP/E Ratio\nP/B Ratio\nMarket Cap (B)\nVolume\n52-Week High\n52-Week Low\nYTD Return (%)\n\n\n\n\n0\nAAPL\nTechnology\n1.240\n0.44\n-0.341\n6.09\n37.602627\n60.79108\n3461.518197\n30174153\n237.49\n164.08\n23.571612\n\n\n1\nMSFT\nTechnology\n0.904\n0.79\n0.104\n12.12\n34.281353\n10.738117\n3089.118265\n18442663\n468.35\n362.90\n13.267011\n\n\n2\nGOOGL\nCommunication Services\n1.034\n0.45\n0.366\n7.44\n23.653225\n6.870729\n2188.452037\n18962205\n191.75\n127.90\n29.232873\n\n\n3\nNVDA\nTechnology\n1.657\n0.03\n1.68\n2.12\n68.81604\n61.60895\n3606.152741\n260171855\n149.77\n45.01\n205.268110\n\n\n4\nMETA\nCommunication Services\n1.215\n0.36\n0.374\n21.38\n26.450891\n8.675483\n1416.463647\n9566484\n602.95\n313.66\n62.516795\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n59\nT\nCommunication Services\n0.730\n4.88\nN/A\n1.24\n18.41129\n1.600308\n163.811869\n13924052\n23.20\n15.94\n39.927917\n\n\n60\nNEM\nBasic Materials\n0.531\n2.32\n3.039\n-2.18\nN/A\n1.655244\n49.158210\n6408011\n58.72\n29.42\n7.541056\n\n\n61\nBHP\nBasic Materials\n0.859\n5.59\n0.077\n3.11\n16.807076\n5.914234\n132.929937\n1811485\n69.11\n50.90\n-18.216277\n\n\n62\nRIO\nBasic Materials\n0.617\n6.97\n0.133\n6.59\n9.467375\n1.832305\n99.642450\n1206041\n75.09\n59.35\n-9.906014\n\n\n63\nLIN\nBasic Materials\n0.949\n1.25\n0.009\n13.37\n33.667915\n5.471563\n214.337782\n1828508\n487.49\n396.07\n9.408891\n\n\n\n\n64 rows × 13 columns"
  },
  {
    "objectID": "src/demo-video.html",
    "href": "src/demo-video.html",
    "title": "Demo Video Walkthrough",
    "section": "",
    "text": "An end-to-end walkthrough of the live app with key talking points on features and functionality.",
    "crumbs": [
      "Demo Video"
    ]
  },
  {
    "objectID": "src/demo-video.html#key-features-walkthrough",
    "href": "src/demo-video.html#key-features-walkthrough",
    "title": "Demo Video Walkthrough",
    "section": "Key Features & Walkthrough",
    "text": "Key Features & Walkthrough\n\nOverview: A concise demo showcasing the live app’s end-to-end workflow, from AI-powered financial analysis to automated report generation and email notifications.\nFeature 1: Automated analysis that processes financial data and generates actionable insights.\nFeature 2: An intuitive, interactive interface enabling quick access to key metrics and reports.\nArchitecture & Implementation: Highlights a robust four-layer solution with integrated workflows (team workshops, prompt engineering, data integration, and orchestration).\nNext Steps & Takeaways: Accelerate your deployment with IBM’s technical community. Request a full hands-on demo with Raffi via LinkedIn today!",
    "crumbs": [
      "Demo Video"
    ]
  },
  {
    "objectID": "src/solution_overview/environment.html",
    "href": "src/solution_overview/environment.html",
    "title": "Step Two: Environment Setup",
    "section": "",
    "text": "Environment Setup & External Integrations\nIn this phase, we configure the environment by integrating essential external services:\n\nData Sources & APIs:\nIntegration with Hugging Face for AI model or local model downloads, Gmail for email automation, and Yahoo Finance for real-time data.\nInfrastructure:\nUse of ElasticSearch for fast querying and IBM Code Engine for containerized PDF generation.\n\n\n\nThe setup leverages IBM Cloud services to ensure scalable and reliable performance. watsonx Orchestrate can be deployed as a service on AWS as well.\n\nAWS Marketplace:\nwatsonx Orchestrate on AWS Marketplace\n\n\n\nAI and Automation tools\n\n\n\n\n\n\n\n\nComponent\nPurpose\nUse\n\n\n\n\nwatonx Orchestrate\nWorkflow automation\nEmail distribution, PDF report generation, chat\n\n\nwatsonx Discovery\nData ingestion & search\nTax law updates, data exploration, RAG\n\n\nwatsonx.ai\nAI model hosting and prompt testing\nReport and email generation\n\n\n\n\n\nData Processing Options\n\n\n\nComponent\nUse Case\nConfiguration\n\n\n\n\nwatsonx.discovery\nJSON transformation, Elasticsearch\nConfiguration Guide\n\n\nwatsonx.data + Milvus\nVector storage, similarity search\nSetup Guide\n\n\nCustom Vector DB\nSpecialized indexing needs\nRefer to specific database documentation\n\n\n\n\nSample Elasticsearch Query\n# Query financial data from ElasticSearch\nresponse=$(curl -X GET \"https://&lt;your-elasticsearch-endpoint&gt;/_search\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"query\": {\n      \"match\": {\n        \"document_type\": \"tax_regulation\"\n      }\n    }\n  }')\necho $response\n\n\nSample steps for watsonx.data integration-leverage latest IBM docs\n# Example using watsonx.data with Milvus for vector storage\nfrom pymilvus import connections, Collection\n\n# Connect to Milvus\nconnections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n\n# Define your collection schema (example schema)\nfrom pymilvus import FieldSchema, CollectionSchema\nimport pymilvus\n\nfields = [\n    FieldSchema(name=\"id\", dtype=pymilvus.DataType.INT64, is_primary=True),\n    FieldSchema(name=\"embedding\", dtype=pymilvus.DataType.FLOAT_VECTOR, dim=128)\n]\ncollection_schema = CollectionSchema(fields, description=\"Collection for financial documents\")\n\n# Create the collection\ncollection = Collection(name=\"financial_documents\", schema=collection_schema)\nprint(\"Collection created:\", collection.name)\n\n\nIBM Documentation Links\n\nIBM Cloud Object Storage:\nCloud Object Storage Documentation\nIBM Code Engine:\nCode Engine Documentation\nElasticSearch on IBM Cloud:\nElasticSearch Documentation",
    "crumbs": [
      "Solution Overview",
      "Environment"
    ]
  },
  {
    "objectID": "src/solution_overview/prepare.html",
    "href": "src/solution_overview/prepare.html",
    "title": "Step One: Prepare – Technical Architecture Overview",
    "section": "",
    "text": "What We’re Building\nThis solution leverages a multi-layered architecture that integrates watsonx.ai, watsonx.discovery, and watsonx.orchestrate. The architecture comprises:\n\nData Layer: Ingests structured and unstructured data into Cloud Object Storage.\nProcessing Layer: Utilizes LLMs (e.g., Mixtral, BYOM Falcon) for dynamic report and email generation.\nIntegration Layer: Employs watsonx.orchestrate for automating workflows such as Gmail and PDF generation.\nInterface Layer: Provides an intuitive UI for real-time insights and actions.\n\n\n\n\nEnvironment Requirements\n\n\n\nComponent\nVersion\nPurpose\n\n\n\n\nIBM Cloud CLI\nLatest\nResource management\n\n\nDocker\n20.10+\nContainer management\n\n\nPython\n3.8+\nApplication runtime\n\n\nGit\n2.0+\nVersion control\n\n\n\n\n\nInitial Setup\n# Install IBM Cloud CLI\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n\n# Install required IBM Cloud plugins\nibmcloud plugin install container-service\nibmcloud plugin install code-engine\n\n\nDeployment Options\n\n\n\nDeployment Type\nInfrastructure\nDocumentation\nUse Case\n\n\n\n\nIBM Cloud (SaaS)\nManaged Services\nIBM Cloud Docs\nQuick start, managed scaling\n\n\nOn-Premise\nOpenShift\nSoftware Hub Install\nAir-gapped environments\n\n\nHybrid\nCustom Mix\nHybrid Guidelines\nEnterprise flexibility\n\n\n\n\nIBM Documentation Links\n\nIBM Cloud Object Storage:\nGetting Started with IBM Cloud Object Storage – Learn how to provision and configure your storage service.\nwatsonx.ai Runtime:\nwatsonx.ai Runtime Documentation – Details on setting up and integrating AI models.\nwatsonx Discovery:\nwatsonx Discovery Documentation – Understand search and data exploration capabilities.\nwatsonx Orchestrate:\nwatsonx Orchestrate Documentation – Explore automated workflow management.",
    "crumbs": [
      "Solution Overview",
      "Prepare"
    ]
  },
  {
    "objectID": "src/implementation_methodology/steptwo-imp.html",
    "href": "src/implementation_methodology/steptwo-imp.html",
    "title": "Step Two",
    "section": "",
    "text": "Step Two Implementation\nThe second phase focuses on deploying AI models and orchestration workflows. This includes:\n\nCustom Hugging Face model deployment in watsonx.ai.\nIntegration of watsonx components via API controls.\nConfiguration of prebuilt and custom workflows for TLH reporting.\nDevelopment of modular skills for PDF generation and email workflows.\n\n\n\nDocumentation Links\n\nHugging Face Integration Guide\nwatsonx.ai Model Deployment Guide",
    "crumbs": [
      "Implementation Methodology",
      "Step Two"
    ]
  },
  {
    "objectID": "src/implementation_methodology/stepone-imp.html",
    "href": "src/implementation_methodology/stepone-imp.html",
    "title": "Step One",
    "section": "",
    "text": "Step One Implementation - The How\nImplementation begins with data management and real-time retrieval setup. This includes configuring ElasticSearch queries for data ingestion, implementing FIFO methodology for unrealized gains/losses, and establishing tax-compliant algorithms for wash-sale rules. The system uses RAG architecture integrated with watsonx Discovery for improved data processing.\n\n\nIBM Documentation Links\n\nElasticSearch Query Configuration Guide\nIBM Cloud Object Storage Setup Guide",
    "crumbs": [
      "Implementation Methodology",
      "Step One"
    ]
  },
  {
    "objectID": "src/implementation_methodology/stepthree-imp.html",
    "href": "src/implementation_methodology/stepthree-imp.html",
    "title": "Step Three",
    "section": "",
    "text": "Step Three Implementation\nFinal implementation involves setting up professional-grade output generation using:\n\nWatsonx Orchestrate custom skill for formatting and branding.\nPDF Generation Application in IBM Code Engine.\nDynamic tables for financial clarity.\nAI-driven natural language understanding for financial queries.\n\n\n\n\nIBM Documentation Links\n\nCode Engine Guide\nPDF Generator app\nWatson Assistant Natural Language Understanding Guide",
    "crumbs": [
      "Implementation Methodology",
      "Step Three"
    ]
  },
  {
    "objectID": "src/key-takeaway.html",
    "href": "src/key-takeaway.html",
    "title": "Key Takeaways",
    "section": "",
    "text": "Best Practices\nThe solution demonstrates successful integration of:\n\nContext-aware report generation combining RAG and generative AI.\nAdvanced portfolio optimization with tax-compliant algorithms.\nAutomated personalized client communications using custom BYOM.\nReal-time data retrieval and processing capabilities.\n\nImplementation best practices include:\n\nUsing collaborative prototyping of workflows for personas and use cases.\nIterating prompt design for structured content generation.\nLeveraging open-source starter kits for BYOM deployment.\nMaintaining modular architecture for scalability and efficiency.\n\n\n\nReusable Assets\nInclude:\n\nYahoo Finance API code\nMixtral configurations\nPrompt templates",
    "crumbs": [
      "Key Takeaways"
    ]
  },
  {
    "objectID": "src/solution_overview/troubleshooting.html",
    "href": "src/solution_overview/troubleshooting.html",
    "title": "Step Three: Troubleshooting & FAQ",
    "section": "",
    "text": "Troubleshooting & Common Issues\nThis section covers typical challenges and their solutions:\n\n\n\nIssue\nEnvironment\nPossible Cause\nSolution\nDocumentation Link\n\n\n\n\nModel Deployment Failure\nIBM Cloud\nIncorrect API keys or IAM settings\nVerify API key configuration and IAM permissions\nIAM Guide\n\n\nData Ingestion Error\nOn-Premise\nMisconfigured endpoints\nCheck storage configuration and credentials\nNetwork Setup\n\n\nAPI Connection Timeout\nHybrid\nIncorrect endpoint or firewall rules\nReview endpoint configurations and network settings\nHybrid Setup\n\n\n\nThe solution implements AIOps principles with modular architecture and containerized deployments. GitHub manages version control for workflow updates, including the Recommendation Engine and Compliance Module. The system includes debugging processes and rapid deployment walkthroughs, with configuration management for watsonx Discovery, Mixtral, and Bring Your Own Model (BYOM) components from Hugging Face.\n\n\n\nInfrastructure Flexibility\nThis solution can be deployed on: - IBM Cloud (demonstrated here) - AWS (using services like S3, Lambda) - Azure - On-premise using Red Hat OpenShift - Air-gapped environments via IBM Software Hub\n\nIBM Documentation Links for Troubleshooting\n\nGitHub Workflow Management:\nGitHub Actions Documentation\nwatsonx Discovery Troubleshooting:\nwatsonx Discovery Troubleshooting Guide",
    "crumbs": [
      "Solution Overview",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "src/landing_page/landing_page.html",
    "href": "src/landing_page/landing_page.html",
    "title": "Project Name",
    "section": "",
    "text": "Project Name\nSubtitle\n\n\nOur Documentation \n\n\n\n\n\nNext Steps\n\n\n\nL ink 1\n\n\n\nLink 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "007 AI Financial Advisory",
    "section": "",
    "text": "RK",
    "crumbs": [
      "Problem Definition"
    ]
  },
  {
    "objectID": "index.html#getting-started-prerequisites",
    "href": "index.html#getting-started-prerequisites",
    "title": "007 AI Financial Advisory",
    "section": "Getting Started / Prerequisites",
    "text": "Getting Started / Prerequisites\nBefore diving in, ensure you have access to IBM Cloud, the necessary API keys, and a basic understanding of AI and data integration. This guide is designed for developers ready to implement a real-world solution with clear, step-by-step instructions.",
    "crumbs": [
      "Problem Definition"
    ]
  },
  {
    "objectID": "index.html#the-why",
    "href": "index.html#the-why",
    "title": "007 AI Financial Advisory",
    "section": "The Why",
    "text": "The Why\nFinancial advisors operate in a rapidly changing regulatory and market environment, where clients expect personalized, tax-efficient, and well-diversified strategies. Constantly shifting tax regulations, market volatility, and manual processes create a perfect storm that makes it difficult for advisors to:\n\nStay compliant.\nDeliver optimal portfolio outcomes.\nEfficiently communicate and scale services to multiple clients.\n\n\n\nProblem Details\nAdvisors face issues like keeping up with tax regulations, managing portfolio diversification, and timely communication—all compounded by market volatility and regulatory risks. This guide outlines how automation and AI can help mitigate these challenges.\n\n\n\nAdditional Context\nThese challenges were identified during a feasibility assessment using local LLMs (e.g., Llama 3.2, Granite 3.0 via ollama) and collaborative workshops. The goal is to streamline operations, reduce compliance risks, and augment financial advisor processes with AI and automation.",
    "crumbs": [
      "Problem Definition"
    ]
  },
  {
    "objectID": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:ElasticSearchDataIngestion_f3d7ryAtQ.html",
    "href": "tax-loss-harvesting-optimization-main/Python Notebooks/notebook:ElasticSearchDataIngestion_f3d7ryAtQ.html",
    "title": "007 AI Financial Advisor",
    "section": "",
    "text": "pip install elasticsearch requests numpy sentence-transformers\n\nRequirement already satisfied: elasticsearch in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (8.14.0)\nRequirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (2.32.2)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (1.26.4)\nRequirement already satisfied: sentence-transformers in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.3.1)\nRequirement already satisfied: elastic-transport&lt;9,&gt;=8.13 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from elasticsearch) (8.13.1)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (1.26.19)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests) (2024.8.30)\nRequirement already satisfied: transformers&lt;5.0.0,&gt;=4.41.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch&gt;=1.11.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub&gt;=0.20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (2023.10.0)\nRequirement already satisfied: packaging&gt;=20.9 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml&gt;=5.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence-transformers) (4.11.0)\nRequirement already satisfied: sympy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from torch&gt;=1.11.0-&gt;sentence-transformers) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers&lt;5.0.0,&gt;=4.41.0-&gt;sentence-transformers) (2023.10.3)\nRequirement already satisfied: tokenizers&lt;0.21,&gt;=0.20 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers&lt;5.0.0,&gt;=4.41.0-&gt;sentence-transformers) (0.20.3)\nRequirement already satisfied: safetensors&gt;=0.4.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers&lt;5.0.0,&gt;=4.41.0-&gt;sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib&gt;=1.1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn-&gt;sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn-&gt;sentence-transformers) (2.2.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2-&gt;torch&gt;=1.11.0-&gt;sentence-transformers) (2.1.3)\nRequirement already satisfied: mpmath&gt;=0.19 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from sympy-&gt;torch&gt;=1.11.0-&gt;sentence-transformers) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport types\nimport pandas as pd\nimport ibm_boto3\nfrom botocore.client import Config\nimport json\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\n\nCloud_Object_Storage_cx_client = ibm_boto3.client(\n    service_name='s3',\n    ibm_api_key_id='ADD YOUR API KEY HERE',\n    ibm_service_instance_id='crn:v1:bluemix:public:cloud-object-storage:global:a/255bb8163fa943e89de4555de2a7d13c:2a47ec7f-8695-42ae-bedd-8b091e397eea::',\n    ibm_auth_endpoint='https://iam.cloud.ibm.com/identity/token',\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.us-south.cloud-object-storage.appdomain.cloud'\n)\nbucket = '007tlhdata'\nobject_key = 'json_customer_data/all_customers_data.json'\n\nbody = Cloud_Object_Storage_cx_client.get_object(Bucket=bucket, Key=object_key)['Body'].read()\n\n\n# Decode the body into JSON\ndata = json.loads(body)\n\n\nall_customer_data = json.loads(body)\n\n\nimport tempfile\nfrom elasticsearch import Elasticsearch\nimport math\nfrom elasticsearch import Elasticsearch\n\n\n# Create an Elasticsearch client\nes = Elasticsearch(\n    \"https://93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud:31018\",\n    verify_certs=False,\n    basic_auth=(\"ibm_cloud_4a5c6b85_9b6b_4332_9b9b_03278e2ed106\", \"35eda2f56e83b1c775a50e98cc711dfd1c7533b5f23232086eea2285f774f5fe\")\n)\n\n/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud:31018' using TLS with verify_certs=False is insecure\n  _transport = transport_class(\n\n\n\nfrom elasticsearch import Elasticsearch, helpers\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\n# Define index name\nindex_name = \"customer_portfolios\"\n\n# Step 1: Create Index with Mapping\ndef create_index():\n    mapping = {\n        \"mappings\": {\n            \"properties\": {\n                \"Customer ID\": {\"type\": \"keyword\"},\n                \"Executive Summary\": {\n                    \"properties\": {\n                        \"Customer Profile\": {\n                            \"properties\": {\n                                \"Risk Tolerance\": {\"type\": \"keyword\"},\n                                \"Preferred Sectors\": {\"type\": \"text\"},\n                                \"Investment Goals\": {\"type\": \"keyword\"}\n                            }\n                        },\n                        \"Portfolio Summary\": {\n                            \"properties\": {\n                                \"Total Current Value\": {\"type\": \"double\"},\n                                \"Net Unrealized Gain/Loss\": {\"type\": \"double\"}\n                            }\n                        }\n                    }\n                },\n                \"Portfolio Summary\": {\n                    \"properties\": {\n                        \"Total Initial Investment\": {\"type\": \"double\"},\n                        \"Total Current Value\": {\"type\": \"double\"},\n                        \"Net Unrealized Gain/Loss Percent\": {\"type\": \"double\"}\n                    }\n                },\n                \"combined_embedding\": {\n                    \"type\": \"dense_vector\",\n                    \"dims\": 384  # Matches the embedding dimensions\n                }\n            }\n        }\n    }\n\n    if not es.indices.exists(index=index_name):\n        es.indices.create(index=index_name, body=mapping)\n        print(f\"Index '{index_name}' created successfully!\")\n    else:\n        print(f\"Index '{index_name}' already exists!\")\n\n# Step 2: Generate Embeddings\ndef generate_embedding(text):\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    embedding = model.encode(text)\n    return embedding.tolist()  # Convert to list for Elasticsearch\n\n# Step 3: Ingest Data\ndef ingest_data(data):\n    for record in data:\n        customer_id = record[\"Customer ID\"]\n\n        # Combine text fields for embedding generation\n        combined_text = (\n            str(record[\"Executive Summary\"]) +\n            str(record.get(\"Portfolio Summary\", \"\")) +\n            str(record.get(\"Tax Loss Harvesting Analysis\", \"\")) +\n            str(record.get(\"Reinvestment Recommendations\", \"\"))\n        )\n\n        # Generate embeddings\n        embedding = generate_embedding(combined_text)\n\n        # Add embedding to the record\n        record[\"combined_embedding\"] = embedding\n\n        # Index the document\n        es.index(index=index_name, id=customer_id, body=record)\n\n    print(\"Data ingested successfully!\")\n\n# Main Execution\nif __name__ == \"__main__\":\n    all_customer_data = json.loads(body)\n    create_index()\n    ingest_data(all_customer_data)\n\n/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n  warnings.warn(\n/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n  warnings.warn(\n\n\nIndex 'customer_portfolios' created successfully!\n\n\n/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n  warnings.warn(\n\n\nData ingested successfully!\n\n\n/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/urllib3/connectionpool.py:1063: InsecureRequestWarning: Unverified HTTPS request is being made to host '93c0666f-8d7e-4e02-8033-be74f8b98de7.c5km1ted03t0e8geevf0.databases.appdomain.cloud'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n  warnings.warn("
  }
]